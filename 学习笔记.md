# #写在前面

永远学习！学习尼采！

[TOC]



# 1、**WebSocket 与 纯 Socket（TCP）的核心区别**

| **特性/区别项** | **WebSocket**                      | **纯 Socket (TCP)**                        |
| --------------- | ---------------------------------- | ------------------------------------------ |
| 协议栈          | 应用层协议，基于 TCP               | 传输层协议（TCP）直接暴露                  |
| 握手方式        | HTTP 请求升级：Upgrade: websocket  | 无 HTTP 握手，通常直接由程序控制连接流程   |
| 使用对象        | 浏览器 / JS 原生支持               | 只能通过底层语言（C/C++/Java等）使用       |
| 连接建立权限    | 受限于同源策略、CORS               | 无浏览器安全限制                           |
| 编程复杂度      | 简单（前端new WebSocket(url)）     | 复杂，需要手动管理流、粘包、协议           |
| 消息边界        | 有明确的消息边界（帧）             | 没有，需自己定义协议格式                   |
| 安全性          | 支持 wss:// 加密                   | 需要手动集成 TLS                           |
| 默认端口        | ws: 80，wss: 443                   | 自定义，一般是任意非保留端口               |
| 应用场景        | IM、协同编辑、实时游戏、推送系统等 | 高性能原生应用、自定义协议传输、高频交易等 |

# 2、ws:// 和wss://

| ws://  | WebSocket（明文）        | ❌ 不加密            | 默认端口 80  |
| ------ | ------------------------ | ------------------- | ------------ |
| wss:// | WebSocket Secure（加密） | ✅ 基于 TLS/SSL 加密 | 默认端口 443 |

# **3、为什么客户端（浏览器、Electron 等）能识别？**

浏览器内置支持 WebSocket 协议，创建连接时使用：

const socket = new WebSocket('wss://example.com/ws');

```
这个 URI 是标准定义的一部分，浏览器会自动处理协议握手，包括：
	•	建立 TCP 连接
	•	发起 HTTP Upgrade 请求（从 HTTP/HTTPS 切换为 WebSocket 协议）
	•	建立全双工通道（像 socket 一样双向收发）

wss 的本质是：先用 HTTPS 握手，然后“升级”到 WebSocket 协议的加密版本
```

# 4、为什么不全用websocket

```
	1.	REST 更适合请求-响应模型
	•	获取用户资料、上传头像、获取新闻列表，这类操作天然就是「请求一下 → 给我响应」；
	•	用 REST + HTTP，配合浏览器缓存、CDN、负载均衡效率更高。
	2.	WebSocket 不走传统的 HTTP 基础设施
	•	不能走 CDN；
	•	很难缓存；
	•	基于长连接，服务端要维护状态（高并发下负担更重）；
	•	如果被 NAT / 防火墙断开，需要专门机制重连；
	3.	安全管控复杂
	•	REST 接口天然有很多 HTTP 安全机制可以复用（如 CORS、Auth headers、OAuth2）；
	•	WebSocket 鉴权得自己封装协议，一旦写错容易出安全漏洞。
	4.	调试和监控困难
	•	REST 请求天然可以抓包（curl / Charles），有标准日志格式；
	•	WebSocket 的数据是“全包体”，抓包、调试、排错更难，需要专门工具。
```

| **功能类型**             | **推荐方式** | **原因**           |
| ------------------------ | ------------ | ------------------ |
| 登录、注册、获取用户资料 | REST         | 简单、幂等、可缓存 |
| 拉取历史聊天记录         | REST         | 偶发请求、可分页   |
| 收发消息、推送           | WebSocket    | 实时性高           |
| 心跳、在线状态同步       | WebSocket    | 实时               |
| 图片上传、文件下载       | REST         | 有内容体、有 CDN   |

# 5、什么是CDN

CDN（Content Delivery Network，内容分发网络）是一个**分布式的缓存系统**，它的核心作用是：



> **让用户更快、更稳定地访问静态资源或网站内容**。

你的网站服务器在北京，有个广州的用户打开你的网站，加载首页时要从北京跨省去拉一张图片，速度慢、延迟高，还容易丢包。

**加了 CDN 后：**

- 这张图片会被缓存到广州本地的 CDN 节点上；
- 当广州用户请求这张图时，会直接从「广州 CDN 节点」拉数据，不用再跑去北京服务器。

CDN 一般用来缓存**不怎么变的资源**：

- 图片 / 视频 / 音频
- JS、CSS、字体文件
- Web 前端打包好的 HTML 文件
- 甚至 REST 接口的响应（例如新闻列表）

```
	1.	用户请求静态资源（如 https://cdn.example.com/logo.png）；
	2.	CDN 节点检查是否有缓存；
	•	有缓存 → 直接返回；
	•	没缓存 → 去源服务器拉一份，保存一份，再返回；
	3.	之后同样请求都会直接从 CDN 返回。
```

# 6、为什么说只有rest可以走CDN呢

说“只有 REST 可以走 CDN”并不是技术上的绝对限制，而是**出于 CDN 的设计目标、协议特性和工程现实的归纳总结**。下面我用直白 + 真实架构视角告诉你原因

| **协议/接口类型**      | **是否适合 CDN** | **原因**                   |
| ---------------------- | ---------------- | -------------------------- |
| REST (GET)             | ✅ 非常适合       | 可缓存、短连接、响应可预测 |
| REST (POST/PUT/DELETE) | 🚫 通常不缓存     | 有副作用，响应多变         |
| WebSocket              | 🚫 不适合         | 长连接、实时通信、无法缓存 |
| gRPC-stream / Socket   | 🚫 不适合         | 同样是持久连接             |

REST 的 GET 请求通常是：

- GET /api/news/today
- GET /api/user/123/profile

这些数据是**一段时间内稳定的**，可以被缓存几分钟甚至几小时 —— 非常适合 CDN 的缓存机制。

请求之间**无状态**，CDN 处理方便，边缘节点可以就近响应用户。

根本原因：无状态

# 7、gRPC和socket的关系

gRPC 和 socket 是两种完全不同层级和抽象的通信方式 —— 它们的**本质区别在于「协议层级」和「开发模型」**：

| **项目** | **gRPC**                              | **Socket**                  |
| -------- | ------------------------------------- | --------------------------- |
| 协议层级 | 应用层（基于 HTTP/2）                 | 传输层（TCP / UDP）         |
| 传输协议 | HTTP/2 + Protobuf                     | 原始 TCP/UDP                |
| 抽象程度 | 高，自动生成代码、支持服务/方法调用   | 低，需要自行管理连接、协议  |
| 支持特性 | 流控、多路复用、负载均衡、双向流、TLS | 全部手写（或自建）          |
| 典型场景 | 微服务通信、跨语言 RPC                | 聊天、游戏、IoT、实时推送等 |
| 复杂度   | 接近「调用函数」级别                  | 接近「操作裸字节流」级别    |

也就是说一个是封装成函数级别了，另一个需要自己拿出来消息解析消息内容再做处理，gRPC相当于是在socket上的封装

gRPC 本质是为 服务间调用 而设计，socket 是为 通信连接 而设计

```
	•	gRPC 最适合的场景是后端服务间调用，例如：
	•	用户服务调用订单服务
	•	文件服务请求认证服务
	•	而 socket 是为高实时通信设计的，比如：
	•	聊天系统（IM）
	•	游戏联机
	•	实时行情推送
	•	视频弹幕、直播弹幕
```

# 8、为啥游戏系统不用websocket而生原生socket呢

**核心原因可以归结为三个字：性能、控制、灵活性。**

**延迟敏感性极高（WebSocket 传输开销大）**

- WebSocket 基于 HTTP 升级建立连接，且**每个数据包都有头部开销**（掺杂帧结构等）。
- FPS、MOBA 类游戏要求 **几十毫秒级的响应时间**，WebSocket 的封装 +底层 TCP 三次握手、拥塞控制等导致延迟波动大。

✅ 所以游戏常用 UDP 或自定义 TCP 协议来规避这些问题。

原生 socket（尤其是 UDP）能实现：

| **功能**                 | **WebSocket 是否支持** | **原生 socket 是否支持** |
| ------------------------ | ---------------------- | ------------------------ |
| 自定义可靠性机制         | ❌ 不支持               | ✅ 支持（尤其是 UDP）     |
| 控制重传 / 丢包处理逻辑  | ❌ 不支持               | ✅ 支持                   |
| 细粒度传输优化（如 MTU） | ❌ 不支持               | ✅ 支持                   |
| 半连接/无连接模式        | ❌ 仅全双工连接         | ✅ TCP/UDP 自由选择       |

# 9、Websocket从http升级的时候，之后的消息还是会用http格式还是全新的消息格式呢

**WebSocket 握手（Upgrade）阶段**

1. **客户端发起 HTTP 请求**，带上特殊的头部 Upgrade: websocket，表示想升级协议：

   ```
   GET /chat HTTP/1.1
   Host: server.example.com
   Upgrade: websocket
   Connection: Upgrade
   Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
   Sec-WebSocket-Version: 13
   ```

   

2. **服务器响应**，同意升级，返回 HTTP 101 Switching Protocols 状态码：

```
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=
```

**升级成功后 — 消息格式变了**

- **此后客户端和服务器间的数据传输**不再使用 HTTP 格式（无请求行、无头部、无状态码），
- 而是使用**WebSocket 帧（frame）格式**，一种专门设计的二进制消息格式。

**WebSocket 帧的结构（RFC 6455）**

每条消息封装成一组帧，主要字段（简化版）：

| **字段名**   | **长度（位）** | **说明**                                      |
| ------------ | -------------- | --------------------------------------------- |
| FIN          | 1              | 是否为消息的最后一帧                          |
| RSV1-3       | 3              | 保留位（一般为0）                             |
| Opcode       | 4              | 帧类型，如文本(0x1)、二进制(0x2)、关闭(0x8)等 |
| Mask         | 1              | 是否对数据进行了掩码处理（客户端必须掩码）    |
| Payload Len  | 7/16/64        | 负载长度                                      |
| Masking-key  | 0 或 32        | 掩码密钥                                      |
| Payload Data | 可变           | 实际消息数据                                  |

- **客户端发送文本消息 "Hello"：**

二进制帧数据（简化伪代码）：

```
0x81 0x85 <masking-key(4 bytes)> <masked "Hello" bytes>
```

WebSocket 协议层在 TCP 连接上独立运行，不涉及 HTTP 的请求行和响应头

# 10、掩码在websocket协议里面的作用是什么呢？

掩码（masking）在 WebSocket 协议里**并不提供安全保护**，它只是防止代理服务器缓存和篡改数据的机制，而不是加密。

简单来说：

- 掩码只是一个简单的异或操作，黑客如果截获数据和掩码，**很容易恢复原始内容**。
- 它的目的**不是防止窃听或破解**，而是防止代理缓存“误判”WebSocket数据为普通HTTP内容。
- 如果你想防止黑客窃听或篡改，必须用 **TLS（即WSS协议）** 来加密通信。
- WSS 是 HTTPS 上的 WebSocket，数据在传输过程中被加密，第三方无法轻易解密。

# 11、用wss的时候，消息体格式是什么样子

简单说，WSS（WebSocket Secure）是在 WebSocket 基础上加了 TLS 加密层。消息体本质上还是**WebSocket帧**的格式，只不过：

- 传输层被 TLS 加密了，网络上的数据包是加密的，看不懂。
- TLS 在 WebSocket帧**外层**，客户端和服务器之间建立安全通道。
- WebSocket协议的帧结构、掩码、分片等机制不变，但数据内容在传输时被 TLS 加密

# 12、TLS加解密原理是什么

### **1.** **握手阶段（Handshake） — 建立安全通道**

TLS连接的第一步是握手，双方协商加密算法、生成密钥。

- **客户端Hello**：客户端发送支持的TLS版本、加密套件列表、随机数（Client Random）等信息。

- **服务器Hello**：服务器选择TLS版本、加密套件，返回服务器证书（包含公钥）、随机数（Server Random）。

- **服务器证书验证**：客户端验证服务器证书的合法性（是否被受信任的CA签名，是否过期等）。

- **密钥协商**：

  

  - 传统TLS（如RSA）由客户端生成一个“预主密钥”（Pre-Master Secret），用服务器公钥加密发给服务器，服务器用私钥解密得到预主密钥。
  - 现代TLS（如ECDHE）使用椭圆曲线Diffie-Hellman交换算法，双方协商一个共享密钥。

  

- **生成会话密钥**：客户端和服务器用握手中的随机数和预主密钥，独立计算出相同的对称加密密钥（Session Key）。

握手成功后，双方使用**对称密钥**加密后续通信数据，极大提升效率。

### **2.** **对称加密通信**

- 之后所有通信数据都用协商好的对称加密算法（如AES）和密钥加密。
- 对称加密速度快，适合传输大量数据。
- 每条消息还会带有消息认证码（MAC）保证数据完整性。

### 3、**消息认证**

- 使用消息认证码（MAC）或基于AEAD的加密（如AES-GCM）同时完成加密和完整性校验，防止数据被篡改。
- 收到消息后，接收方先校验MAC，确保数据未被篡改，再解密。

### 4、**证书和身份认证**

- 服务器通过CA签发的证书证明自己的身份，客户端通过验证证书保证自己连接的是目标服务器，防止中间人攻击。

# 13、为啥他们沟通的密钥只有他们双方知道呢？密钥本身如何被加密呢？

### **1. 非对称加密保护密钥（RSA密钥交换）**

在早期TLS版本中，密钥交换通常用RSA：

- 客户端生成一个随机的“预主密钥”（Pre-Master Secret）。
- 用服务器的**公钥**加密这个预主密钥，然后发给服务器。
- 服务器用自己的**私钥**解密得到预主密钥。

因为只有服务器有私钥，别人截获了密文没法解密，**密钥本身通过非对称加密被保护**。

### **2. Diffie-Hellman密钥交换（DH/ECDHE）——双方各自生成秘密参数，协商共享密钥**

现代TLS（TLS 1.2/1.3）更推荐使用**Ephemeral Diffie-Hellman（临时DH）**，简称ECDHE：

- 双方分别生成一个私有秘密值（私钥），并计算对应的公钥（公开给对方）。
- 通过交换公钥，各自用自己的私钥和对方的公钥计算出相同的共享密钥（Session Key）。
- 这个共享密钥**没有直接传输**，即使第三方截获了所有通信数据，包括公钥，也无法计算共享密钥（这是数学难题）。

所以这里的“密钥只有双方知道”是因为共享密钥是**双方私钥和对方公钥计算出来的**，而私钥绝不会离开各自设备。

# 14、为什么各自的私钥和对方的公钥算出来的共享密钥是相同的呢？

假设：

- 公共参数是一个大质数 p 和一个生成元 g，公开给双方。
- **Alice** 选择一个私钥 a，计算公钥 A = g^a \mod p，把 A 发送给 Bob。
- **Bob** 选择一个私钥 b，计算公钥 B = g^b \mod p，把 B 发送给 Alice

![image-20250606234924587](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250606234924587.png)

![image-20250606235013548](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250606235013548.png)

# 15、TLS握手建立完安全通道之后，基于这个通道的HTTP通信还需不需要三次握手？

答案是：**不需要了**。

详细解释：

- **TCP三次握手**是建立TCP连接的，是网络层的事情。
- **TLS握手**是在已经建立的TCP连接基础上，协商加密参数，建立安全会话。
- **HTTP通信**（比如HTTPS）是在TLS连接之上的应用层数据传输。

所以：

- 三次握手只发生一次，是TCP连接建立时。
- TLS握手紧接着TCP连接建立完成后进行。
- 之后的所有HTTP请求和响应都是在这条已经建立的安全TCP连接（TLS通道）里传输的。

举个类比：

TCP三次握手像是打开了电话线路；TLS握手像是双方约定说用加密语言交流；之后的HTTP数据就是这条加密线路上的“电话交谈”。通话期间不需要再重新建立电话线路（三次握手）。

**如果HTTP连接断开（TCP断开），重新连接时才会重新三次握手，紧接着TLS握手，然后HTTP通信。**

# 16、利用drogon库的websocket例子

```cpp
#include <drogon/drogon.h>

class MyWebSocketHandler : public drogon::WebSocketController<MyWebSocketHandler>
{
public:
    // 绑定路由，匹配 /ws 路径的 WebSocket 请求
    void handleNewConnection(const drogon::WebSocketConnectionPtr &conn) override
    {
        LOG_INFO << "New WebSocket connection established: " << conn->getPeerAddr().toIpPort();
    }

    void handleConnectionClosed(const drogon::WebSocketConnectionPtr &conn) override
    {
        LOG_INFO << "WebSocket connection closed: " << conn->getPeerAddr().toIpPort();
    }

    void handleMessage(const drogon::WebSocketConnectionPtr &conn,
                       std::string &&message,
                       const drogon::WebSocketMessageType &type) override
    {
        LOG_INFO << "Received message: " << message;
        // 简单回显收到的消息
        if (type == drogon::WebSocketMessageType::Text)
        {
            conn->send(message);
        }
        else if (type == drogon::WebSocketMessageType::Binary)
        {
            conn->send(std::move(message), drogon::WebSocketMessageType::Binary);
        }
    }

    WS_PATH_LIST_BEGIN
        WS_PATH_ADD("/ws")  // 监听 /ws 路径
    WS_PATH_LIST_END
};

int main()
{
    // 注册 WebSocket 控制器
    drogon::app().registerController(std::make_shared<MyWebSocketHandler>());

    // 监听端口，启动服务
    drogon::app().addListener("0.0.0.0", 8080);
    drogon::app().run();

    return 0;
}
```

收到的参数为string，但是type 是以下三种之一：

| **枚举值**                   | **含义**                 |
| ---------------------------- | ------------------------ |
| WebSocketMessageType::Text   | 文本消息（UTF-8 字符串） |
| WebSocketMessageType::Binary | 二进制消息（任意字节流） |
| WebSocketMessageType::Pong   | Pong 控制帧（应答 Ping） |

- 对于 Binary 类型，虽然是 std::string 类型，你不能直接当 UTF-8 文本来处理，应以字节方式解析。
- Drogo 是为了方便，统一用 std::string 存储字节内容，但你要自己区分 Text 与 Binary。

# 17、所以我其实有必要在websocket层上包装协议吗

**原因不是 WebSocket 不够用，而是它提供的是“低层通信通道”，需要你自己定义上层语义。**

WebSocket 本身只定义了：

- 建立连接、收消息、发消息（文本 / 二进制）；
- 没有内建的消息格式、命令字、状态码、序列号等机制；
- 没有区分“登录消息”、“心跳消息”、“聊天消息”等。

**你必须构建自己的协议语义层，否则前后端根本无法协同工作。**

#### **1.** **JSON 协议封装（简单易调试）**

```
{
  "type": "chat_message",
  "from": "user123",
  "to": "user456",
  "timestamp": 1728391723,
  "content": "Hello!"
}
```

- 客户端、服务端解析 type 字段进行分发；
- 可以支持 ping / pong / auth / chat_message / logout 等类型；
- 容易扩展，适合中小型系统。

#### 2、**protobuf 或自定义二进制协议（高性能 + 安全）**

```
message Packet {
  required uint32 type = 1; // 登录、心跳、消息、通知等
  required bytes payload = 2;
}
```

- 每个 type 映射一种 payload 的反序列化格式；
- 能节省字节开销、加快处理速度；
- 配合 protobuf、flatbuffers 等工具生成代码

# 18、lock-free队列

```cpp
struct Node {
    int data;
    std::atomic<Node*> next;
};

std::atomic<Node*> head;

void push(int val) {
    Node* new_node = new Node{val, nullptr};
    do {
        Node* old_head = head.load();
        new_node->next = old_head;
    } while (!head.compare_exchange_weak(new_node->next, new_node));
}
```

这里是比较的new_node->next和head是否一致，如果一致，就把head设置为new_node

用这个写日志不会导致顺序性问题吗？

> **入队顺序 ≠ 时间戳顺序**

> 所以如果**两个线程写日志的时间非常接近**，但因为调度原因**晚写的日志先入队**，就会出现**日志输出顺序不等于时间先后顺序**。



------



**那为什么主流日志系统（glog、spdlog、log4cpp 等）**

**都接受这种“入队顺序为准”的设计？**

**✅ 原因一：**

**性能优先，时间差异容忍**

- **日志系统的主要目标是服务于问题排查、性能分析、审计等**
- 在**高并发系统**中，要求日志精确按纳秒时间排序是不现实的
- 日志系统采用 **“先到先写”** 策略，是为了保证 **高性能、低锁开销、无丢失**

**✅ 原因二：**

**系统时间本身不可靠**

- 多线程写入时，调用 std::chrono::high_resolution_clock 或 gettimeofday，并非全局同步
- 系统调用获取时间本身也有抖动
- 多核 CPU 下线程可能在不同核上运行，时间戳抖动是常态

**✅ 原因三：**

**“顺序”是人为假设，而非绝对真理**

- 用户通常是**按线程 ID + 时间粗粒度**来观察日志（秒/毫秒）
- 微观上的时间不一致对绝大多数场景没有影响

0lock-free队列取

> **既然能 lock-free 插入，也能 lock-free 弹出。**

取出逻辑依赖 **原子指令（如 CAS：compare-and-swap）** 来修改头指针，流程大致如下：

```cpp
Node* old_head = head;
Node* new_head = old_head->next;
while (!head.compare_exchange_weak(old_head, new_head)) {
    // 如果有竞争，old_head 会被自动更新为新的 head，再重试
    new_head = old_head->next;
}
```

如果我更新成功了，那么head就设置为newhead了，这个时候我就可以处理这个数据了

而且这样其实没有什么顺序问题，因为对于日志而言关键的是保证单个线程的日志是顺序的就行，而lock-free对于单个线程而言其顺序肯定是有保障的

# 19、atomic的compare_exchange_weak是如何保证原子的？

std::atomic::compare_exchange_weak 是 C++ 提供的原子操作，**其原子性是由 CPU 指令级别支持保证的**，不会被编译器优化掉或被线程打断。

核心依赖的是 CPU 的指令，比如：

- **x86 架构**：使用 LOCK CMPXCHG 指令（Compare and Exchange）
- **ARM 架构**：使用 LDREX/STREX 或 CAS 指令

这些指令在硬件层面保证：

1. 比较 + 替换 是一条不可拆解的操作
2. 在多核系统中会锁住总线或使用 cache coherency 协议来防止并发冲突

| **类型** | **含义**                                                     | **是否可能虚假失败** | **使用场景**           |
| -------- | ------------------------------------------------------------ | -------------------- | ---------------------- |
| weak     | 可能因为 CPU 的**伪共享、缓存同步失败**返回 false，即使实际值匹配 | ✅ 可能虚假失败       | 循环重试性能更好       |
| strong   | 严格对比值，不允许虚假失败                                   | ❌ 不会虚假失败       | 少数需要稳定行为的场景 |

## 20、什么是internal TLS证书

“**Internal TLS 证书**” 通常指的是：

> **用于公司/组织内部系统通信的 TLS 证书**，而不是由公认的第三方证书机构（CA，如 DigiCert、Let’s Encrypt）签发的

| **特性**                 | **描述**                                                     |
| ------------------------ | ------------------------------------------------------------ |
| 📜 自签名 or 私有 CA 签发 | 不被浏览器或操作系统默认信任                                 |
| 🔒 加密功能完整           | 依然使用标准 TLS/SSL 加密协议，通信内容加密、完整性校验都没问题 |
| 🔁 适用于内网环境         | 内部服务之间加密通信，例如微服务之间、CI/CD 工具之间         |
| ⚠️ 不适合公网客户端       | 浏览器访问时会报 “证书不受信任” 错误                         |

因为不是公有 CA 签发，客户端不会自动信任，需要：

- 手动导入到客户端的信任列表（如浏览器或系统根证书库）
- 在 curl 等客户端中用 --insecure 或指定 --cacert
- Electron 等内嵌浏览器中禁用证书校验（**仅开发时可用**）

# 21、CA是什么，为什么他们可以发布证书呢？操作系统为何自动信任这些证书？

CA 是「证书颁发机构」（Certificate Authority），它的职责是：

> **给域名、组织、网站、服务器颁发数字证书，证明它们的身份是真实可信的。**

证书里包含：

- 所属域名（如 auth.chat.com）
- 公钥（用于 TLS 加密）
- 有效期、签名算法
- 由哪个 CA 签名（也就是谁担保了这张证书）

## **为什么操作系统或浏览器会信任 CA 签发的证书？**

### **✅ 根本原因：**

### **CA 的根证书预装在系统/浏览器中**

- macOS / Windows / Linux 都内置了几十~上百个 CA 的根证书
- Chrome / Firefox 等浏览器也自带了自己的 CA 信任列表

只要你访问的网站使用的证书是「由这些根证书签发或链式签发」，就被认为是 **可信的**

# 22、为什么证书只带着公钥？那么服务端的私钥是从何而来呢？

**证书只包含公钥，是为什么？**

因为：

- **证书是公开的身份声明**，就像身份证上的信息
- 它包括公钥，是为了让**客户端用来加密数据或验证签名**
- **私钥是秘密，只能服务端自己保管**

### **✅ 所以：**

- 证书：公开的，包含 服务端身份 + 公钥
- 私钥：服务端自己持有，**绝不能在证书中公开**

证书生成过程如下：

1. 服务端生成一对密钥对（私钥 + 公钥）
2. 把「公钥 + 域名信息 + 组织信息」打包成 CSR（证书签名请求）
3. 把 CSR 发给 CA（证书机构）
4. CA 审核通过后，用自己的私钥对这个公钥和信息进行签名，生成一个证书（只包含公钥）
5. 服务端拿着这个证书 + 自己的私钥组合部署上线

# 23、我自己开发的时候搞一个域名chat.auto.com，CA应该不能认证它吧？什么样的域名CA会支持认证呢？

证书颁发机构（CA）在给你签发证书之前，需要验证你**对该域名有所有权或控制权**

| **域名类型**             | **是否支持** | **签发条件说明**                   |
| ------------------------ | ------------ | ---------------------------------- |
| yourcompany.com          | ✅            | 你控制 DNS 或网站内容              |
| api.yourcompany.com      | ✅            | 同上，子域名也行                   |
| chat.auto.com            | ❌            | 如果 auto.com 不属于你，就不能申请 |
| localhost                | ❌            | 本地地址，CA 不会签发              |
| *.yourcompany.com        | ✅            | 通配符证书，需要验证控制整个域名   |
| 私人局域网域名如 dev.lan | ❌            | 不被公网 CA 支持，除非自建 CA      |

## **为什么不支持自定义域名如** 

## **chat.auto.com**

因为 CA 不知道你是否**真正拥有 auto.com 的权利**。

CA 是全网信任体系的一部分，不能随便签发别人的域名。否则就会导致伪造、钓鱼攻击等安全灾难

# 24、那么本地或者开发如何使用https也就是TLS加密呢？

### **1. ✅ 用自签证书（开发常用）**

你可以自己生成一个自签名证书用于 chat.auto.com，并配置浏览器信任（或绕过）。缺点是浏览器会提示“不受信任”。

可用工具如：

- [mkcert](https://github.com/FiloSottile/mkcert)：快速生成受本机信任的开发用证书
- openssl 自己手写一份 CA 和证书

💡 你可以配合 /etc/hosts 把 chat.auto.com 映射到本机 IP，然后用自签证书调试。

### **2. ✅ 用可信域名 + 动态 DNS（线上测试常用）**

你也可以申请一个免费域名并指向自己的公网 IP，然后通过：

- Let’s Encrypt（免费 CA）
- ZeroSSL（免费证书）

来申请真正有效的 HTTPS 证书。

# 25、免费域名并指向自己的公网 IP是啥意思

#### **1. 申请一个免费域名（或使用子域名服务）**

| **平台**                                              | **类型**                     | **是否支持免费 HTTPS**    |
| ----------------------------------------------------- | ---------------------------- | ------------------------- |
| [Freenom](https://www.freenom.com)                    | .tk, .ml 等免费顶级域名      | ✅ 配合 Let’s Encrypt 使用 |
| [DuckDNS](https://www.duckdns.org)                    | 子域名（如 xxx.duckdns.org） | ✅ 提供 API 更新动态 IP    |
| [Cloudflare Pages + DNS](https://www.cloudflare.com/) | 免费 DNS 管理                | ✅ 支持 HTTPS、自签、API   |

#### **2. 将域名指向你的公网 IP**

登录你注册域名的 DNS 面板，把 A 记录设置为你的公网 IP。例如

chat.example.tk →  123.45.67.89

# 26、什么是A记录

A记录（Address Record，地址记录）是 **DNS（域名系统）中的一种资源记录类型**，它的作用是：

👉 **把域名解析成一个 IPv4 地址**。

你访问网站的时候，会先向 DNS 查询这个域名的 A记录，得到类似

chat.example.com → 123.45.67.89

之后浏览器才会向这个ip发起请求

- AAAA记录 是 IPv6 地址的版本；
- CNAME记录 是给域名起别名（如 www.chat.com → chat.com）；
- A记录 是最常用的基础记录，适用于你有具体 IP 的场景（比如云服务器、虚拟机）

# 27、DNS服务器由谁部署

DNS 服务器不是由某一个统一机构部署的，它是一个 **层级分布式系统**，不同层级由不同组织或个人负责。下面是结构和责任分层

### **1.** **根 DNS 服务器（Root DNS Servers）**

- 由全球 13 个主根服务器（名字从 A 到 M）提供服务。

- 由一些国际组织负责运营，比如：

  

  - Verisign（管理 A 根服务器）
  - ICANN（负责 IANA）
  - 美国国防部、NASA、Netnod（瑞典）等。

  

✅ 它是 DNS 的起点，告诉你 .com、.cn、.org 等顶级域名的服务器在哪里

2、**顶级域名服务器（TLD Servers）**

- 由各类顶级域名的管理机构运营：

  

  - .com 由 Verisign 管理
  - .cn 由 CNNIC（中国互联网络信息中心）管理
  - .org 由 Public Interest Registry 管理

  

它告诉你：chat.com 属于哪个域名注册商的服务器。

### **3.** **权威 DNS 服务器（Authoritative DNS Server）**

- 这是你购买域名后配置的 DNS 服务器：

  

  - 如果你用阿里云买的域名，那它的权威 DNS 服务器是阿里云的；
  - 用 Cloudflare、DNSPod、GoDaddy，也是由它们提供。

  

✅ 它最终回答：chat.example.com → IP 地址是多少

# 28、是让每个rest请求独立写处理逻辑，还是说分成大模块如用户管理，然后通过请求类型来细分操作更好？

所有用户相关请求统一走 /api/user

**优点：**

- **接口聚合**：一个模块一个入口，逻辑集中。
- **扩展灵活**：新增 action 不需要注册新接口。
- **便于网关管理 / 统一转发**：可适配自定义协议或 RPC 框架习惯。
- **前后端协定简洁**：只需维护 action 类型和参数规范。

**⚠️ 缺点：**

- RESTful 规范性较差（非标准 REST 风格）。
- 在大型系统中可能**不易拆分为微服务**，接口粒度太粗。
- 可读性下降：接口文档需要额外说明每个 action 的行为。
- 路由级权限控制粒度不够细。

多个路由分别注册的好处：

- 清晰直观，接口语义明确。
- 容易接入文档系统（Swagger/OpenAPI）。
- 便于使用中间件做接口级权限控制和限流。
- 适合给第三方开放 API 接口。

# 29、get和post难道只有传参的区别吗？他们没有协议上的区别吗？或者说他们只有规范性的区别？post也可以当做get用？

**GET 和 POST 并不只是“参数放哪”的区别，而在 HTTP 协议语义、行为、缓存、安全等层面，都有显著不同**

| **对比点**                   | **GET**                           | **POST**                         |
| ---------------------------- | --------------------------------- | -------------------------------- |
| **语义**                     | 获取资源                          | 提交数据（创建/处理）            |
| **幂等性**                   | 是（同一个请求重复执行结果一样）  | 否（每次请求可能有不同副作用）   |
| **参数位置**                 | URL 查询字符串（?a=1&b=2）        | 请求体（body）                   |
| **缓存**                     | **浏览器和代理可以缓存**          | **通常不缓存**                   |
| **浏览器历史记录**           | 参数被保存（URL）                 | 不保存 body 参数                 |
| **长度限制**                 | 受 URL 长度限制（一般 2KB - 8KB） | **几乎无限制（服务器配置上限）** |
| **用途**                     | 查询、搜索、获取内容              | 提交表单、用户认证、文件上传     |
| **是否可被预取（prefetch）** | 是，可能会被浏览器/代理提前发起   | 否                               |

- **GET**:

  > “The GET method means retrieve whatever information is identified by the URI.”

  

  - 不应产生副作用
  - 可以安全重试

  

- **POST**:

  > “The POST method is used to request that the origin server accept the enclosed entity as a new subordinate of the resource identified by the URI.”

## **总结：不是只有参数区别，而是：**

- **语义**：获取 vs 提交
- **幂等性**：GET 是幂等的，POST 不是
- **缓存行为**：GET 可以缓存，POST 不行
- **浏览器行为**：GET 会记录完整 URL，POST 不会
- **安全性**：POST 更适合提交敏感数据（如登录）

# 30、http请求有很多字段，我必须关注哪些？



## **1. 请求行（Request Line）**

<Method> <Request-URI> <HTTP-Version>

GET /api/v1/user?id=123 HTTP/1.1

- HTTP-Version: 常见为 HTTP/1.1（或 HTTP/2, HTTP/3）

## **2. 请求方法（Method）**

| **方法** | **语义**                     | **幂等性** | **用途**     |
| -------- | ---------------------------- | ---------- | ------------ |
| GET      | 获取资源                     | ✅          | 查询数据     |
| POST     | 创建资源 / 执行非幂等操作    | ❌          | 新建、登录等 |
| PUT      | 替换整个资源                 | ✅          | 覆盖更新     |
| PATCH    | 局部更新                     | ✅          | 修改某些字段 |
| DELETE   | 删除资源                     | ✅          | 删除资源     |
| OPTIONS  | 获取服务器允许的操作（CORS） | ✅          | 跨域预检等   |



## **3. 常见请求头（Headers）**

### **3.1 通用头部**

| **Header**      | **描述**                        |
| --------------- | ------------------------------- |
| Host            | 请求的主机名（必须）            |
| User-Agent      | 客户端信息                      |
| Accept          | 客户端期望的返回类型（如 JSON） |
| Accept-Encoding | 支持的压缩格式（如 gzip）       |
| Connection      | 如 keep-alive                   |

### **3.2 请求体相关**

| **Header**     | **描述**                        |
| -------------- | ------------------------------- |
| Content-Type   | 请求体格式，如 application/json |
| Content-Length | 请求体长度（自动计算）          |

| **Content-Type**                  | **描述**            |
| --------------------------------- | ------------------- |
| application/json                  | JSON 格式（最常见） |
| application/x-www-form-urlencoded | 表单数据            |
| multipart/form-data               | 上传文件、图像等    |

### **3.3 认证相关**

| **Header**    | **描述**                 |
| ------------- | ------------------------ |
| Authorization | Bearer <token> 认证头    |
| Cookie        | 携带 session/csrf 等信息 |

# 31、对于每一个rest接口都应该通过token鉴权吗?除了login以外?

### **为什么需要 token 鉴权？**

- **身份验证（Authentication）**：识别用户是谁（token = 身份凭证）。
- **权限控制（Authorization）**：不同用户权限不同（如 admin 和普通用户接口访问权限不同）。
- **防止伪造请求（CSRF）**：token 是防止伪造请求的重要方式。
- **安全隔离上下文**：避免未授权用户访问敏感资源（如用户信息、订单、消息、资产等）。

### **哪些接口可以不鉴权？**

只有极少数接口可以不鉴权，典型场景：

| **接口路径** | **是否鉴权** | **理由**                                   |
| ------------ | ------------ | ------------------------------------------ |
| /login       | ❌            | 用户还未登录，无法携带 token               |
| /register    | ❌            | 用户还未注册，同上                         |
| /health      | ❌（可选）    | 健康检查接口，部署或监控用（但可限流保护） |
| /public/*    | ❌            | 静态资源或公开数据接口                     |

# 32、如何防止一个接口被恶意轰炸调用呢？

防止接口被恶意轰炸（即 **API 滥用、刷接口、DDoS 攻击**）是实际开发中的重要一环。一般我们采取 **限流 + 认证 + 防刷机制** 多管齐下。下面是系统性思路：

## **一、限流（Rate Limiting）**



### **1. IP 限流（最基础）**

- 每个 IP 每分钟最多调用 N 次接口
- 超过返回 429 Too Many Requests

- Nginx / Caddy 限流模块（推荐入口层做）
- Redis + Lua 脚本（如漏斗、令牌桶算法）

### **2. 用户级限流（更细粒度）**

- 每个 token / 用户 ID 每分钟最多请求 N 次
- 防止用户用代理IP绕过

实现方式：

- Redis 计数器 user:<uid>:api_count + TTL
- 使用中间件拦截请求进行计数 + 判断

## **二、验证码 + 登陆行为验证（针对登录、注册类接口）**

- 图形验证码（防止自动化脚本刷接口）
- 滑块/行为验证（如极验）
- 手机/邮箱验证码限制发送频率（例如每分钟1次，每小时5次）

## **三、token/签名校验**

- 对所有接口强制验证 token
- 参数签名机制：带时间戳 + HMAC 签名，防止重放攻击

## **四、反爬策略**

- 对异常请求增加 **响应延迟**
- 检测 UA / Referer 不合理的请求
- 接口增加校验字段（如 JS Challenge）

# 32、我这里的lambda应该需要根据req指针来先进行鉴权才进行后面的步骤吧？或者说drogon一般建议怎么做权限校验呢？

```cpp
bool RestWrapper::registerHandler(const std::string& methodName, JsonHandler handler, const std::string& path)
{
    if (!isRouteValid(path)) {
        ERROR("RestWrapper::registerHandler", "fatal error! check your param, path invalid");
        return false;
    }
    if (!handler) {
        ERROR("RestWrapper::registerHandler", "handler is empty on registration for path: " + path);
        return false;
    }
    auto httpMethods = std::move(parseHttpMethod(methodName));
    if (httpMethods.empty()) {
        ERROR("RestWrapper::registerHandler", "fatal error! check your param, http method invalid");
        return false;
    }
    auto lambda = [handler](const drogon::HttpRequestPtr& req, std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
        TRACE("lambda of rest", "request path is " + req->getPath() + ", now call the handler!");
        try {
            JsonValue jsonResponse = handler(*req->jsonObject());
            auto httpResponse = drogon::HttpResponse::newHttpJsonResponse(jsonResponse);
            httpResponse->setStatusCode(drogon::k200OK);

            httpResponse->addHeader("Access-Control-Allow-Origin", "*");
            httpResponse->addHeader("Access-Control-Allow-Methods", "GET, POST, OPTIONS");
            httpResponse->addHeader("Access-Control-Allow-Headers", "Content-Type");

            callback(httpResponse);
        }catch(...){
            return;
        }
    };
    TRACE("RestWrapper::registerRoute", "registerHandler, path is " + path + ", method is " + methodName);
    drogon::app().registerHandler(path, std::move(lambda), getConstraintFromMethodVec(httpMethods));
    return true;
}
```

解决方法：

应该提供多种过滤器，由客户端自行选择不同的过滤器

```
drogon::app().registerHandler(
    "/api/secure",
    yourHandler,
    {drogon::Get},
    {"AuthFilter", "RateLimitFilter"}  // ✅ 支持多个过滤器，按顺序执行
);
```

# 33、我看到很多公司的实现的请求rest接口里面带着？以及参数，为什么他们不把参数放到消息体中？

你看到的那种带 ? 的 URL（如 /api/user?id=123&token=abc）是 **HTTP GET 请求的查询参数**。这种形式和将参数放在消息体中的 POST 请求不同，是 REST 规范中两种常见的参数传递方式。

###  **一、****GET 请求的语义要求参数在 URL 中**

RESTful 风格的设计强调：

- **GET 请求用于查询资源**，应**不携带请求体**，参数通过 URL 传递。
- **POST/PUT/PATCH/DELETE 等请求才推荐带 body 数据。**

这符合 HTTP 协议本意，也有很多基础设施（CDN、浏览器缓存、爬虫）对 GET 请求的 URL 有优化。

### **二、URL 参数更直观、可缓存、可复用**

- URL 参数清晰暴露调用意图：

  /api/search?keyword=ai&page=2

  → 一眼就能看懂在搜什么。

- 可以被浏览器缓存：GET 请求有 idempotent（幂等）语义，适合缓存。

- 可以被搜索引擎收录、用于分享、链接等

# 34、为什么这里的内存应该存入redis而非本地缓存

```cpp
JsonValue UserMgr::sendRegisterEmailVerifyCode(const JsonValue& req)
{
    std::string email = Utils::Json::JsonUtils::toString(req["email"]);
    if (email.empty()) {
        ERROR("UserMgr::sendRegisterEmailVerifyCode", "fatal error! email is empty");
        JsonValue ret;
        ret["ret"] = -1;
        ret["message"] = "email is empty";
        return ret;
    }
    if (!isValidEmail(email)) {
        ERROR("UserMgr::sendRegisterEmailVerifyCode", "fatal error! email is invalid");
        JsonValue ret;
        ret["ret"] = -1;
        ret["message"] = "email is invalid";
        return ret;
    }
    std::string code = toSendRegisterEmailVerifyCode(email);
    storeCodeToCahce(email, code);
    JsonValue ret;
    ret["ret"] = 0;
    ret["message"] = "send register email verify code success";
    return ret;
}
```

| **方案**                       | **问题**                                               |
| ------------------------------ | ------------------------------------------------------ |
| 仅使用 C++ 内存（如 std::map） | 只能在本进程中使用，**重启丢失**，**不支持分布式部署** |
| 使用 Redis（推荐）             | 分布式共享、支持 TTL 过期、稳定、可监控                |

# 35、编译问题：为何找不到json/json.h

头文件的查找顺序是：

### **查找路径顺序（以 GCC/Clang 为例）**

1. **编译器默认的系统 include 路径**（比如 /usr/include）；
2. **通过 -I 参数手动指定的路径**；
3. **pkg-config 或 CMake 中 include_directories() 指定的路径**；
4. **依赖的库路径（比如 /usr/include/jsoncpp/json/json.h）**；

在项目根加上这个就可以了 但是具体原因还是不详 因为之前是能正常使用的

```
cmake_minimum_required(VERSION 3.10)
project(CHAT)

set(CMAKE_CXX_STANDARD 17)
include_directories(SYSTEM /usr/include/jsoncpp)

add_subdirectory(main)
add_subdirectory(modules)
add_subdirectory(Utils)



```

# 36、cpp的redis客户端选择

- **你是开发业务逻辑、微服务的后端** → 用 redis-plus-plus，现代接口，开发效率高。
- **你只需要 Redis 做验证码、临时缓存等功能** → 用 redis-plus-plus，几行代码搞定。
- **你是写库、系统底层组件、希望无第三方依赖** → 可以直接用 hiredis，但你要自己封装管理资源。

# 37、集群内也就是局域网的连接比如连接到redis节点这种还需要TLS加密吗

> **内网不是天然安全的**，你要根据数据敏感性、网络拓扑和合规要求来判断是否使用 TLS。默认部署可不开，但如果涉及用户数据、跨组织访问或长远维护，建议上 TLS。很多大厂（如字节、腾讯）现在内网服务都在逐步 mTLS 化。

如果你希望做到“安全默认”，最好在部署平台层（比如 Istio、NGINX、Caddy）实现 **sidecar TLS 加密**，而不是 Redis 自己开 TLS。这样能统一管理证书和密钥。

# 38、已经通过make install安装的库如何干净清除呢？例如我已经安装了不带ssl的redis++，但是现在又想加入ssl如何重新安装呢？

删除之前的库的安装目录

```
sudo rm -rf /usr/local/redis/redis-plus-plus
```

检查其余相关路径

```
# 如果你之前没指定路径，可能默认是这些
sudo rm -rf /usr/local/include/sw/redis++
sudo rm -f /usr/local/lib/libredis++.*
sudo rm -rf /usr/local/lib/cmake/redis++
```

# 39、既然通过apt下载的hiredis无法用于继续构建其他的库，那么提供这种方式的意义在哪里？

当你要构建 **依赖它的其他现代 CMake 库（如 redis++）**，apt 安装就会显得“残缺”：

| **问题**                                   | **原因**                                                     |
| ------------------------------------------ | ------------------------------------------------------------ |
| 缺少 hiredisConfig.cmake 等 CMake 支持文件 | apt 只提供静态库 + 头文件，不考虑 CMake 项目依赖链           |
| 无法被 find_package(hiredis) 找到          | CMake 查找模块失败，导致构建失败                             |
| 不好管理安装路径                           | 无法和用户自定义的库集成安装路径统一（例如 redis++ 的安装目录） |

**那为什么** **apt** **包不把这些东西一起提供？**

因为 Debian/Ubuntu 的打包哲学是：

> **只打最核心的东西**，如头文件 + .so，但不会关注第三方现代 CMake 生态。

再加上：

- hiredis 本身并不是设计为 CMake-first 的库（虽然近年加了 CMake 支持）；
- 早期很多人都是直接用 make 而不是 CMake；
- 系统包的维护者对 redis++、libhv、cpp-httplib 等生态不关心。

所以打包出来的 libhiredis-dev 就是个**最小功能集**，不是为了服务现代 CMake 构建的依赖关系。

卸载方法：

```
sudo apt remove --purge libhiredis-dev
```

然后安装目录下的lib include share目录

# 40、redis基本操作

### 1、配置

支持连接配置和连接词配置

### 2、字符串操作

```c++
redis.set("key", "value");
auto val = redis.get("key"); // 返回 std::optional<std::string>
redis.incr("counter");
redis.append("key", "more");
redis.mget({"k1", "k2"}, std::back_inserter(vec));
```

### 3、哈希表

```cpp
redis.hset("hash", "field", "value");
auto val = redis.hget("hash", "field");
redis.hgetall("hash", std::inserter(map, map.begin()));
redis.hdel("hash", "field");
```

### 4、列表

```cpp
redis.rpush("list", {"v1", "v2"});
auto val = redis.lpop("list");
redis.lrange("list", 0, -1, std::back_inserter(vec));
```

### 5、集合

```cpp
redis.sadd("set", {"a", "b"});
auto is_member = redis.sismember("set", "a");
redis.smembers("set", std::inserter(set, set.begin()));
```

### 6、有序集合

```cpp
redis.zadd("zset", "member", 1.5);
redis.zrange("zset", 0, -1, std::back_inserter(vec));
redis.zrem("zset", "member");
```

### 7、发布订阅

```cpp
 sw::redis::Redis redis("tcp://127.0.0.1:6379");
 redis.publish("chat", "Hello, this is a test message!");


sw::redis::Subscriber sub = redis.subscriber();
sub.on_message([](std::string chan, std::string msg) {
    std::cout << "Received: " << msg << std::endl;
});
sub.subscribe("chat");
sub.consume(); // 阻塞等待
```

### 8、**事务（Transaction）**

```cpp
auto tx = redis.transaction();
tx.set("key", "v1");
tx.incr("counter");
auto replies = tx.exec(); // 提交并获得结果
```

### 9、**管道（Pipeline）**

```cpp
auto pipe = redis.pipeline();
pipe.set("k1", "v1").get("k1").incr("counter");
auto replies = pipe.exec();
```

#### 10、高级发布订阅

支持 pattern 订阅、消息回调、断线重连等场景：

```cpp
sub.on_pmessage(...);
sub.psubscribe("chat.*");
```

### 11、redis集群操作

```cpp
sw::redis::RedisCluster cluster("tcp://127.0.0.1:7000");
cluster.set("key", "value");
```

# 41、我当前进程的redis只是连接到了集群的一个节点对吧，也就是说即使用cluster，redis集群应该也至少在一个机架内?他们的数据是同步的？

```
sw::redis::RedisCluster redis("tcp://127.0.0.1:7000");
```

这行代码只**连接到了集群中的一个节点**，但 redis-plus-plus 会通过该节点**自动发现集群中的其它节点**（通过 CLUSTER NODES 命令）并根据 key 的 hash slot **自动路由操作到正确节点**。

你不用手动处理分片路由，这由 redis-plus-plus 封装好了。

### 集群中的数据是同步的吗？

**不是所有数据都同步。**

在 Redis Cluster 中：

- 数据按照 **hash slot** 分布在多个主节点上（16384 个 slot）。
- **每个主节点保存一部分 slot 的数据**。
- **每个主节点有 0～N 个副本节点**（slave 或 replica）。
- **主从之间数据是异步复制的**。

也就是说：

> 如果你在集群中 set("user:123", "abc")，这个 key 会被 hash 到一个特定 slot，然后 Redis 会将这个写请求路由到对应的主节点。

然后主节点会**异步**地将数据复制到它的从节点

### **Redis Cluster 适合部署在一个机架内吗？**

**不是必须的，但实际中建议“一个数据中心的多机部署”。**

- Redis Cluster 设计上是支持跨机部署的。

- 但**集群节点间需要极高的可达性和低延迟**，因为：

  

  - 节点间需要频繁发送 PING/PONG 心跳（每秒10次）。
  - 网络抖动容易导致故障切换（failover）。

> 所以 **大多数公司会把 Redis 集群部署在同一个数据中心的不同服务器上**，而不是跨城市/机房/云厂商

- 如果你部署的是 **Redis Cluster**，不建议用于 **Pub/Sub**，因为 Pub/Sub 不支持跨 slot。
- 你可以独立部署一个 **Redis 单节点**，专用于消息队列（Pub/Sub、Stream）。

# 42、使用redis集群，如何保证数据一致性呢？因为可能写入和查询的不是一个节点呢？

Redis Cluster 是**共享无中心（sharding）**架构，它把 16,384 个哈希槽分配到多个节点。每个节点负责部分 key 的读写。

这就带来两个问题：

1. **客户端写入一个 key 到节点 A**
2. **另一个客户端读取相同 key，但连接的是节点 B**

⚠️ 如果 B 不是 key 所属槽的主节点，读取将失败或读取旧值（从节点延迟）

| **特性**                         | **说明**                                |
| -------------------------------- | --------------------------------------- |
| 弱一致性（eventual consistency） | 主从之间为异步复制，从节点可能有延迟    |
| 哈希槽绑定 key                   | 保证同一个 key 的所有操作都在一个节点上 |
| 客户端 slot 路由                 | 客户端通过 MOVED 重定向找到正确节点     |
| 无分布式事务（非原子跨 key）     | 多 key 不保证原子性，除非位于同一 slot  |

## **Redis Cluster 如何**基本保证一致性

1. **每个 key 的操作在固定节点上执行**（hash slot 决定了 key 路由）

   → 不存在“同一个 key 写多个节点”的问题。

2. **客户端接收到 MOVED 响应后，会重新路由**到正确节点

   → 依赖客户端的自动重定向能力（多数语言的 Redis Cluster 客户端支持）。

3. **写操作写入主节点，由主节点异步复制给从节点**

   → 只要客户端连接的是主节点，不会看到旧数据



> 不建议开启从节点读，除非你能接受 eventual consistency。

## **如何增强一致性保障？**

### **1.** **客户端只连主节点**

- 禁止从节点读
- 保证数据最新

> ✅ 推荐 Redis Cluster 客户端设置：readonly=false

# 43、这里说的redis主节点和从节点分别是什么

### **主节点（Master）**

- **职责**：处理所有读写请求，是**数据写入的唯一来源**。
- **数据源头**：数据变更（SET, DEL, HSET, etc.）都发生在主节点。
- **同步机制**：会将数据异步地**复制（replicate）**到它的从节点。
- **在 Redis Cluster 中**：每个 hash slot 会分配一个主节点。

### **从节点（Replica / Slave）**

- **职责**：仅处理只读请求（默认），主要作用是**备份数据**或做**读扩展**。
- **同步方式**：会从它的主节点拉取数据进行同步，并保持跟主节点的一致性。
- **数据一致性**：是**异步复制**，所以在主从之间可能有**延迟**。
- **容灾意义**：主节点宕机时，从节点可以通过 Sentinel 或 Cluster **自动提升为主节点**

假设你部署了如下结构：

```cpp
Redis Cluster（3 个主节点 + 3 个从节点）：

- Master1 <--> Replica1
- Master2 <--> Replica2
- Master3 <--> Replica3
```

- 每个主节点负责一部分 hash slot。
- 每个从节点**实时复制**对应主节点的数据。
- **某个主节点宕机时，对应的从节点可能被选举为新的主节点**。

### **注意点：**

1. **主从架构用于高可用，不等于负载均衡**（虽然你可以用读写分离方式提升吞吐）。
2. **主从之间不保证强一致性**，所以不能用于需要强事务语义的场景。
3. Pub/Sub 模式下**消息不会从主节点转发到从节点**，所以如果你用了 Cluster 或副本集，**Pub/Sub 消息只在当前连接的节点内有效**。

**如果你只是需要高并发读，单主多从就够了；但如果要支持写扩展和自动分片，才需要用 Redis Cluster**

# 44、为什么需要单主多从？单主单从不就行了？

### **1.** **读写分离，提升读性能*

- 单主单从，所有读写请求都落在一台机器上，性能有限，读多写少时读请求很容易成为瓶颈。
- 单主多从，将读请求分散到多个从节点，明显提升整体系统的读吞吐量。业务上很多场景读远多于写，比如缓存查询、热点数据访问等。
- 这是最常见、最经济的扩展读能力方案。

### **2.****容灾和高可用**

- 单主单从若主机挂了，服务立刻不可用。
- 单主多从，多个从节点中可以提升主节点，一个从节点宕机对整体影响小。配合哨兵(sentinel)或类似机制，从节点能自动提升为主节点，实现自动故障恢复。
- 这极大增强了系统的可用性和容错能力。

### **3.** **写压力瓶颈依然存在，但读瓶颈可缓解**

- 单主多从没有写的水平扩展，写压力全靠主节点，但一般写压力比读压力小得多，这样配置就能满足绝大部分业务需求。
- 如果写压力过大，才考虑 Redis Cluster 做多主分片。

### **4.** 成本和复杂度折中**

- 多主集群（Redis Cluster）运维复杂，设计和客户端也更复杂，适合大规模写场景。
- 单主多从相对简单，性价比高，易于运维

# 45、redis单主多从数据不一致如何解决呢？

单主多从架构下，数据一致性问题的核心原因是**主节点写入成功后，从节点异步复制，存在一定延迟**，导致从节点数据可能暂时落后于主节点。这种“**最终一致性**”特性带来的不一致，解决或缓解的思路有：

### **1.** 

**理解 Redis 的复制机制**

- Redis 默认异步复制：主节点写成功后就返回，不等待从节点确认。
- 这意味着写操作可能在从节点尚未复制完成前就被读取，出现“读脏数据”或“旧数据”的风险

### **2.** 

**常见缓解方案**

#### **（1）读写分离时，读请求优先打主节点**

- 对于对数据一致性要求高的读请求，直接去主节点查询，避免读取到旧数据。
- 读写分离一般是业务层设计的选择，**关键数据、强一致场景不做读分离。**

#### **（2）读写分离时，适当延迟读从节点数据**

- 业务层**对某些读请求加延迟**，保证写入传播完成（但会增加延时，体验不好）。

#### **（3）利用 Redis Sentinel 或哨兵自动切换**

- 保证主从切换的过程不会丢数据（基于复制偏移量），减少数据不一致时间窗口。

#### **（4）配置 Redis 复制参数（风险平衡）**

- min-slaves-to-write 和 min-slaves-max-lag：要求主节点至少有一定数量的从节点在一定延迟范围内才允许写入，避免数据丢失。
- 但开启后写性能会受影响。

### **3.** 

**业务层设计**

- 设计“最终一致”或“弱一致”模型，允许短暂数据不一致，依赖业务补偿机制。
- 通过分布式锁、幂等性设计等保证业务正确性

# 46、如何实操部署单主多从的redis集群

## **1. 准备环境**

- 多台服务器或多进程（本地多端口）模拟多节点
- 安装 Redis（推荐版本 ≥ 5.x）
- 配置防火墙允许节点间通信端口（默认 6379）

## 2、**启动主节点 Redis 实例**

- 在主节点机器上启动 Redis，确保配置文件中：

  ```
  port 6379
  bind 0.0.0.0   # 允许远程访问
  protected-mode no   # 关闭保护模式（或配置好密码）
  ```

  redis-server /path/to/redis.conf

## **3. 启动多个从节点 Redis 实例**

- 在从节点机器上，启动 Redis 实例，配置文件示例：

```
port 6380   # 可以不同端口，或者不同机器默认6379
bind 0.0.0.0
protected-mode no
replicaof 主节点IP 6379
```

## **4. 配置密码（可选）**

如果启用了密码（requirepass），从节点还需要配置主节点密码：

```
masterauth 主节点密码
```

## **5. 验证主从同步**

- 登录主节点，写入数据：

  ```
  redis-cli -h 主节点IP -p 6379
  > set key1 "hello"
  ```

  

- 登录从节点，读取数据：

- ```
  redis-cli -h 从节点IP -p 6380
  > get key1
  "hello"
  ```

## **6. 使用 Redis Sentinel 保障高可用**

- 多主从节点部署容易出现单点故障，用 Sentinel 监控自动主从切换。
- Sentinel 配置多台服务器，示例配置：

```
port 26379
sentinel monitor mymaster 主节点IP 6379 2
sentinel auth-pass mymaster 主节点密码
sentinel down-after-milliseconds mymaster 5000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 10000
```

- 启动 sentinel：

  ```
  redis-sentinel /path/to/sentinel.conf
  ```

# 47、glusterFS原理其实就是基于网络的是吧。一个节点做专门的数据存储，然后需要共享卷的时候，配置并且软连接上去？

**GlusterFS 本质上就是一个基于网络的分布式文件系统**，其核心原理可以概括为：**“将多台服务器上的本地文件系统通过网络聚合成一个统一的文件系统”**。你提到的软连接和共享卷是使用方式的一部分，但我们可以更系统地解释它的原理与架构：

### **1.** 

### **基于网络通信（NFS-like，但分布式）**

GlusterFS 的节点之间使用 TCP/IP 或 RDMA 通信，不依赖专用硬件或主从结构，是一个**纯用户态的网络文件系统**。

### **2.** 

### **构建块：Brick**

- **Brick** 是 GlusterFS 的最基本单元，实际上就是**挂载在某个节点上的一个目录**。
- 例如你可以有 /data/brick1 这样的目录作为一个 brick。
- 每个 brick 都运行在 Gluster 节点上，**这些 brick 组成一个逻辑卷（volume）**。

### **3.** 

### **Volume：虚拟卷管理逻辑**

- Volume 是用户真正访问的文件系统视图，它由若干 brick 按某种策略（如分片、复制）组成。

- GlusterFS 提供了多种 Volume 类型：

  

  - **Distributed（分布式）**：将文件分布在不同 brick 上；
  - **Replicated（复制型）**：多个 brick 保存相同数据（如 RAID1）；
  - **Dispersed（纠删码）**：用于容错存储（类似 RAID5/6）；
  - **Striped（条带）**：分散存储一个文件的不同块（大文件优化）。

  | **卷类型**          | **数据分布策略**     | **特点**             |
  | ------------------- | -------------------- | -------------------- |
  | Distributed         | 文件级分布，单份存储 | 扩展性强，但容错性差 |
  | Replicated          | 每份文件复制多份     | 容错强，但空间浪费多 |
  | Dispersed（纠删码） | 数据+校验块分布      | 兼顾容错与空间效率   |
  | Striped             | 大文件分块存储       | 适合大文件吞吐场景   |

### **4.** 

### **挂载访问（客户端视角）**

- 你可以通过 GlusterFS 原生客户端、NFS、SMB 或 FUSE 把 Volume 挂载到本地路径。
- 就像你说的，“**软连接上去**”这一点，在逻辑上类似于客户端通过挂载把远端卷“连接到本地目录”。

### **5.** 

### **元数据去中心化**

- 不像传统分布式文件系统（如 HDFS）有 NameNode，GlusterFS **没有中心元数据服务器**。
- 每个节点都知道部分元数据信息，**通过一致性哈希算法决定文件的位置**，这让它更去中心、但在复杂应用场景下也容易出问题。

在 GlusterFS 里，**数据最后不会只落在一个节点上，而是分布在一组参与存储的“brick”节点上**——这正是它作为“分布式文件系统”的核心意义。你可以把 GlusterFS 看成是一个**“逻辑上的大硬盘”**，这个硬盘底层由很多服务器共同组成，**文件的数据块按策略分布在多个节点上**，而你看到的是统一挂载的路径。

# 48、为什么k8s必须挂载共享卷

## **Kubernetes 并不强制要求共享卷**

- K8s 中的 **Pod 默认是无状态的**，生命周期短暂、不可恢复；
- 如果你的应用是 **无状态服务（如 Web 前端、Stateless API）**，根本不需要挂载任何卷；
- 所以，**挂不挂卷，挂什么卷，是由你的业务需求决定的**。

### 当你运行的是有状态服务（Stateful Service）必须考虑持久化：

| **场景**                     | **为什么需要共享存储**            |
| ---------------------------- | --------------------------------- |
| 数据库（如 MySQL、Postgres） | 容器挂了不能丢数据                |
| 媒体处理（上传、转码）       | 多个 Pod 要读写同一目录           |
| 机器学习训练                 | 持久保存模型/数据集               |
| 日志收集                     | 多个容器集中写入一个持久目录      |
| 缓存/队列持久化              | 防止临时数据丢失                  |
| 多副本读共享数据             | 所有 Pod 需要访问同一份模型或配置 |

# 49、linux网络基本原理

## 1、linux底层的网络原理

**Linux 网络栈架构简图（五层模型）**

```
应用层        → user space    ：curl、ping、nginx
传输层        → 内核空间      ：TCP、UDP
网络层        → 内核空间      ：IP、ICMP
链路层        → 内核空间      ：Ethernet、ARP
物理层        → 驱动层+硬件    ：网卡驱动、PHY 芯片
```

## 2、从应用数据发送数据包到网卡

你可以理解为：

> **用户空间调用 socket → 数据进入内核协议栈 → 一层层封装 → 发送到网卡 → 发出网络**

### **1. 用户空间（Userspace）**

- 应用程序调用 socket()、send() 等系统调用；
- 内核通过 syscall 进入协议栈。

### **2. 内核空间协议栈（Kernel Network Stack）**

- 根据 socket 类型（TCP/UDP），**走不同的传输层逻辑**；
- 然后将数据加上 IP 头（网络层），再加以太网头（链路层）；
- 路由判断目标地址走哪个网卡（通过 route table）；
- 最终调用驱动将封装好的帧交给网卡。

### **3. 网卡驱动（Device Driver）**

- 调用 DMA 将数据放到网卡缓冲区；
- 通过总线（如 PCIe）通知网卡发送数据；
- 网卡硬件将帧发出。

## 3、逆过程

**接收数据流程（逆过程）**

- 网卡收到电信号 → 驱动中断通知内核；
- 内核从网卡 DMA 区读取帧；
- 一层层解包（链路层 → 网络层 → 传输层）；
- 最终把 payload 给到应用程序的 socket 缓冲区。

# 50、git的fork和clone的区别

| **操作** | **clone**          | **fork**                       |
| -------- | ------------------ | ------------------------------ |
| 作用     | 本地复制仓库       | 创建你账号下的独立仓库副本     |
| 影响     | 不在平台上创建记录 | 是平台级别操作，建立上下游关系 |
| 权限     | 可读写（本地）     | 你对 fork 后的仓库拥有完整权限 |
| 适合     | 想本地查看/使用    | 想修改并贡献代码、长期维护变种 |

# 51、pr和mr的区别

| **名称**            | **所属平台**                | **含义**                                  |
| ------------------- | --------------------------- | ----------------------------------------- |
| Pull Request（PR）  | GitHub、Gitee、Bitbucket 等 | “我请求你把我的改动 pull 到你的分支上”    |
| Merge Request（MR） | GitLab                      | “我请求你把我的改动 merge 到你的主分支中” |

 **为什么 GitHub 叫 PR 而 GitLab 叫 MR？**

- **GitHub 的设计哲学更偏开源协作（fork-first model）**，强调“我不是你项目的成员，我请求你 pull 我代码进来”，所以叫 **Pull Request**。
- **GitLab 是面向企业内协作的（branch-first model）**，强调“我们在同一个项目里，我请求合并我的分支”，所以叫 **Merge Request**。

# 52、ubuntu和linux主干之前的关系

> **Linux 是发动机，Ubuntu 是一辆装好了座椅、方向盘、娱乐系统的汽车。**



| **概念**               | **角色**                                                | **维护者**                | **更新频率**          | **功能定位**                         |
| ---------------------- | ------------------------------------------------------- | ------------------------- | --------------------- | ------------------------------------ |
| **Linux 内核（主干）** | 操作系统的核心，处理硬件、内存、进程等                  | Linus Torvalds + 核心社区 | 每 2~3 个月一个稳定版 | 通用、高性能、安全、高度模块化       |
| **Ubuntu**             | Linux 发行版，封装了内核 + 驱动 + 图形界面 + 软件包管理 | Canonical 公司            | 每半年一个正式版本    | 易用性友好、桌面体验好、适合开发环境 |

### **1.** 

### **Ubuntu 是基于 Linux 内核“定制”出来的发行版**

- Ubuntu 每个版本发布时，都会**选定一个特定版本的 Linux 内核作为基础**（比如 6.5、6.8 等）；

- 然后 Canonical 会：

  

  - 添加一些**驱动补丁**（尤其是对特定硬件的兼容）；
  - 集成**GNOME/KDE 桌面环境**；
  - 配置默认服务、网络工具、软件包源等；
  - 打包成 .iso，提供用户安装体验。

  

> 所以，**Ubuntu 是一个“包了皮的 Linux”**，内核还是 Linux，但用户体验被重新包装了。

# 53、我现在安装了ubuntu，可以为其更换kernel吗？

Ubuntu 官方维护了一个叫 **mainline 内核仓库**，你可以从这里下载 .deb 包一键安装

1. 查找你想要的内核版本（比如 6.8.0）；

2. 下载以下 3 类 .deb 文件（必须选和你架构匹配的，比如 amd64）：

   

   - linux-headers-...all.deb
   - linux-headers-...generic.deb
   - linux-image-...generic.deb

3. sudo dpkg -i *.deb

4. 重启然后查看内核版本

# 54、为什么我dpkg安装了内核的deb文件重启就能生效？就像模块加载似的？

你问的这个现象，背后的机制其实挺有意思，但也并不神秘。



**核心点是：**



1. **内核并不会“热加载”你用 dpkg 安装的内核 .deb 包内容。**

   你安装的是完整的内核映像文件和相关模块文件（.deb 包里面通常包含了 vmlinuz 内核镜像、initrd/initramfs、以及模块文件夹 /lib/modules/版本号/），dpkg 只是把它们放到系统指定的位置。

2. **重启是关键。**

   安装完新内核后，你系统里的引导加载程序（如 GRUB）会检测到新的内核镜像并添加启动条目。只有重启时，系统才会真正从这个新的内核映像启动。这个过程相当于把内核代码从磁盘“加载进内存”，并执行。

3. **模块加载与内核加载是不同阶段。**

   你说“就像模块加载似的”，模块加载确实是运行时动态完成的（比如 insmod/modprobe 加载模块），但安装内核 .deb 后，实际上内核是完全替换了：

   

   - 新的内核映像替换了旧的启动文件
   - 新的模块目录替换旧的模块
   - 重启后系统直接用新的内核启动，内核自然会加载对应版本的模块

   

4. **initramfs/initrd 的作用**

   安装内核时通常也会生成一个新的 initramfs（初始化内存文件系统），它是内核启动时用来加载驱动和模块的临时根文件系统。重启后新的 initramfs 也被用上，保证了内核启动环境的完整性。

这个其实像windows重装系统，是系统引导的时候就用了新的内核文件，但是我惊奇的是除内核文件以外的文件仍然可以使用

### **1.** **内核和文件系统是两回事**

- **内核文件**：就是你说的内核映像（vmlinuz）以及相关模块，它们负责操作硬件、管理资源、调度进程等核心工作。
- **文件系统（根文件系统 rootfs）**：是系统的用户空间，存放各种应用程序、配置文件、用户数据等。

### **2.** **为什么“重装内核”后，文件系统里的文件依然存在且可用？**

因为：

- **内核只是系统启动的“心脏”，并不直接决定文件系统的内容**。
- 你通过 dpkg 安装内核只是替换了内核映像和模块文件，**文件系统本身没有改动**，它依然挂载的是之前的那个磁盘分区（比如 ext4、xfs 等），里面的所有文件（比如 /usr、/etc、/home 里的数据）都没变。

换句话说，内核和文件系统是分开管理的：

- 内核被替换了，负责系统核心逻辑；
- 文件系统保持不变，里面的东西没变。

### **3.** **这和 Windows 的“重装”差别很大**

- Windows 里你如果“重装系统”，往往是格式化或覆盖了系统盘，这样用户文件和系统文件都会改动。
- Linux 里换内核，根本不会格式化系统分区，只是替换启动用的内核文件（通常在 /boot 分区或者 /boot 文件夹里），其他目录都是照旧的。

# 55、dpkg命令的原理、是由谁提供的？

dpkg 是 Debian 系列（如 Ubuntu）下的底层包管理工具。它**直接操作 .deb 安装包文件**，比 apt 更底层，不会自动解决依赖。

| **命令**                          | **作用**                             |
| --------------------------------- | ------------------------------------ |
| dpkg -i xxx.deb                   | 安装 .deb 包（不自动安装依赖）       |
| dpkg -r 包名                      | 删除已安装包（保留配置文件）         |
| dpkg -P 包名                      | 完全删除包（含配置文件）             |
| dpkg -l                           | 列出所有已安装包                     |
| `dpkg -l                          | grep xxx`                            |
| dpkg -s 包名                      | 查看某个包的详细信息                 |
| dpkg -L 包名                      | 查看包安装了哪些文件（以及文件位置） |
| dpkg -S 文件路径                  | 反查某个文件属于哪个包               |
| dpkg --configure -a               | 重新配置所有未完成配置的包           |
| dpkg -i --force-overwrite xxx.deb | 强制覆盖文件安装（解决文件冲突）     |

Debian下面的才用这个？

| **系统**            | **特点**                                       |
| ------------------- | ---------------------------------------------- |
| **Debian**          | 正宗本体                                       |
| **Ubuntu**          | Debian 的最大衍生版，最流行的桌面/服务器 Linux |
| **Kali Linux**      | 基于 Debian，专注安全渗透测试                  |
| **Linux Mint**      | 基于 Ubuntu，主打易用桌面体验                  |
| **Deepin / UOS**    | 中国开发，基于 Debian 或 Ubuntu                |
| **Raspberry Pi OS** | 之前叫 Raspbian，也是 Debian 派生              |

###  **非 Debian 系的系统用不了** 

# 56、apt和apt-get的区别

| **对比项**   | apt                                | apt-get                      |
| ------------ | ---------------------------------- | ---------------------------- |
| 出现时间     | 比较新（Ubuntu 16.04 / Debian 8+） | 很早就有（Debian 初期）      |
| 面向用户     | **面向用户**，语法简洁、输出美观   | 面向脚本或高级用户，功能更全 |
| 输出格式     | 美观、有进度条、颜色               | 纯文本                       |
| 功能完整度   | 覆盖 90% 常见场景                  | 功能最全，适合复杂任务或脚本 |
| 推荐使用场景 | 日常使用、交互式操作               | 自动化脚本、系统维护任务     |

apt 合并了很多 apt-get 和 apt-cache 的功能。

apt 没有实现 apt-get 的所有功能，比如 apt-get build-dep、source；

# 57、网卡其实是内置的外设？

## 1**. 从“硬件结构”角度来看**

网卡是**主板之外的“外设”**，但：

- 可以是**插在主板上的 PCIe 设备**（独立网卡）；
- 也可以是**集成在主板芯片组或 CPU 里的**（板载网卡，现代主板几乎标配）；

不管内置还是插卡，它的本质仍是一个**通过总线连接 CPU 的外围设备**，也就是说：

> ✅ **它是外设（Peripheral），只是物理上“内置”了而已。**

## **2. 从“操作系统设备模型”角度来看**

内核并不在乎网卡是插的还是焊的：

- 内核通过 PCI（或 USB、SoC 总线）**枚举所有设备**；
- 然后根据设备 ID 加载对应驱动（例如 e1000e、r8169、iwlwifi 等）；
- 内核给它抽象出一个网络接口，比如 eth0、enp0s3、wlan0；

所以对于操作系统来说，**网卡是一个标准的 I/O 设备，驱动+接口抽象是关键**，至于是不是板载，它不关心。

| **层级**    | **名称**       | **主要职责**                                              | **网卡是否参与** |
| ----------- | -------------- | --------------------------------------------------------- | ---------------- |
| 第1层       | **物理层**     | 电信号/光信号传输，电压、电缆、接口标准（如 RJ45、802.3） | ✅ 是             |
| 第2层       | **数据链路层** | MAC地址、帧结构、以太网校验（CRC）等                      | ✅ 是             |
| 第3层及以上 | 网络层及以上   | IP、TCP、UDP、应用协议等                                  | ❌ 靠内核完成     |

### **它主要负责：**

1. **收发电信号或无线信号**（物理层）；
2. **封装/解封以太网帧、计算校验码、过滤 MAC 地址**（数据链路层）；
3. **中断通知内核有帧到了**；
4. **通过 DMA 把数据拷贝进内存缓冲区**；
5. 然后内核网络子系统（如 net_rx_action）再从内存中读取并往上递交处理

# 58、交换机也工作在物理层+链路层，它和网卡其实是类似的只是他们是作为网络的基础设施？

> 是的，**交换机和网卡确实都工作在物理层和链路层**，它们的职责是类似的：处理**MAC 帧的收发和转发**，只是：

- > **网卡**：工作在主机内部，连接主机和网络；

- > **交换机**：工作在网络内部，连接主机与主机之间，完成帧的转发与隔离。

| **目**   | **网卡（NIC）**                | **交换机（Switch）**         |
| -------- | ------------------------------ | ---------------------------- |
| 工作层   | 物理层 + 数据链路层            | 物理层 + 数据链路层          |
| 数据处理 | 收/发帧、MAC 检查、CRC、帧缓冲 | 学习 MAC、帧转发、广播/泛洪  |
| 处理对象 | 一台主机的帧收发               | 多个主机之间的帧转发         |
| MAC 相关 | 有一个固定 MAC 地址            | 有 MAC 地址表（转发决策）    |
| 协议支持 | 以太网帧处理（802.3）          | 同上，加上如 STP/VLAN 等扩展 |
| 角色     | 主机侧 I/O 接口                | 网络侧流量中枢               |

| **设备**   | **面向对象** | **主要作用**                |
| ---------- | ------------ | --------------------------- |
| **网卡**   | 主机 ↔ 网络  | 帮主机接入网络（输入/输出） |
| **交换机** | 网络 ↔ 网络  | 控制帧在网络中如何被转发    |

# 59、当我用tcp的socket发送大消息的时候，tcp会分片，这个时候发送成功是整个消息都被对方接受到为准还是我们全部发送为准

> **你调用 send() 成功，只代表数据已经送入本地 TCP 发送缓冲区，并不代表对方已经收到或收到完整。**

> TCP 是一个**字节流协议**，会进行**自动分片 + 重组 + 重传保证顺序与完整性**，但**你仍然无法通过 send() 来确认对方收到的完整性**，**只能通过协议或业务层自己来确认“消息完整性”**。

```
send(sock, buffer, len, 0);
```

1. 数据被复制进本地内核的 TCP 发送缓冲区；
2. 操作系统负责把这段数据**切成多个 MSS（最大报文段）大小的片段**；
3. 每片都发给对方；
4. TCP 协议在内核层面自动处理分片、重发、乱序、粘包、ACK 等细节。

| **保证项**   | **说明**                           |
| ------------ | ---------------------------------- |
| ✅ 顺序       | 接收方按发送顺序拼接               |
| ✅ 可靠性     | 丢包会重传，不会丢消息             |
| ✅ 去重       | 同一个段收到多次，只处理一次       |
| ❌ 消息边界   | 不保证一次 send() 对应一次 recv()  |
| ❌ 消息完整性 | 应用必须自行定义消息结构、协议头等 |

也就是说发送端用tcp发送了消息之后，这条消息tcp协议栈能保证消息最终被对方收到，但是受到网络时延的影响，这个时间甚至可能非常慢，甚至持续数个小时重传，也就是接收端持续recv但一直没有有效的结果

**TCP 的哲学是：“我不快，但我一定送到”（unless 被杀死）**

### **1.** **加“应用层超时”机制**

> 你不能盲信 recv() 会在几秒内返回，要用 select() 或 poll() 加超时。

```cpp
// 等待可读事件（3秒）
fd_set fds;
FD_ZERO(&fds);
FD_SET(sock, &fds);
struct timeval timeout = {3, 0};
int ret = select(sock+1, &fds, NULL, NULL, &timeout);
if (ret == 0) {
    // 超时：对方未响应
}
```

### **2.** **定义“心跳协议”或“应用超时”**

> TCP 无法告诉你“对方是否挂了”，你得主动发“心跳包”并设置超时。

```
客户端每隔30秒发送一个 {"type":"ping"}；
服务器如果超过60秒没收到任何包，就断开连接。
```

# 60、服务器网络配置合集

## 1、我如何为我的服务器配置稳定的ip？

| **环境类型**                   | **描述**                         | **配置方式**                            |
| ------------------------------ | -------------------------------- | --------------------------------------- |
| 🖥️ 本地物理服务器 / 虚拟机      | 家用 PC / 公司服务器 / VMware 等 | 配置静态 IP（局域网 or 公网）           |
| ☁️ 云服务器（如阿里云、腾讯云） | 云主机，如 ECS / EC2 / Droplets  | 绑定公网 IP                             |
| 🛜 家用宽带                     | 动态公网 IP（每次拨号变）        | 配置 DDNS 或公网静态 IP                 |
| 📶 移动热点、校园网             | NAT 后私网地址                   | 无法直接实现稳定公网 IP，只能穿透或中转 |

## 2、一般后端服务集群应该只会有少量的公网ip暴露出去吧？甚至只有一个

**为什么“只有少量公网 IP”？**

### **1.** **安全第一：最小攻击面**

- *公网 IP 暴露 = 黑客的入口**；
- 如果每个服务、每台机器都暴露公网 IP，会造成巨大的攻击面；
- 相反，只暴露一个 Nginx 网关或 API Gateway，就可以统一做防火墙、限流、认证、WAF 保护。

### **2.** **节省公网 IP 成本**

- 云服务商通常对公网 IP 单独计费（EIP、流量等）；
- 多个服务共享一个 IP，配合端口/域名路由可节省大量开销。

### **3.** **合理的服务拆分与流量控制**

- 外部客户端请求通过入口节点进来；
- 内部服务之间通过内网通信（通常是 10.x.x.x、172.16.x.x 网段）；
- 可以灵活进行 service discovery、负载均衡、权限控制。

## 3、那既然如此，我服务端内部的ip就是局域网ip啊，按理说我确实可以随意配置

| **条件**                   | **描述**                                       |
| -------------------------- | ---------------------------------------------- |
| ✅ 私网环境                 | 使用 10.x.x.x, 172.16-31.x.x, 192.168.x.x 网段 |
| ✅ 路由可达                 | 所有服务之间 IP 可达（同网段或路由打通）       |
| ✅ 不冲突                   | 没有重复 IP、路由、子网掩码问题                |
| ✅ 服务绑定在这些 IP 上监听 | 比如某服务 bind(192.168.1.10, 8080)            |
| ✅ 配置文件中约定好         | 比如 config.yaml 明确写了服务地址              |

虽然你**可以配置任意私有 IP**，但仍需注意以下问题：

| **问题**         | **描述**                                                     |
| ---------------- | ------------------------------------------------------------ |
| ❌ IP 冲突        | 多台机器手动配置同一个 IP 会造成严重问题                     |
| ❌ 跨网段不可达   | 比如 192.168.1.x 和 192.168.2.x 默认不可达，除非有路由器打通 |
| ❌ 硬编码不可维护 | IP 写死在代码里容易出错，应使用配置中心或 DNS 统一管理       |
| ❌ 多网卡环境混乱 | 一台机器有多个网卡，可能绑定错地址                           |

## 4、这一点其实对我来说很震惊，这相当于一个服务器的ip可以由自己决定

你的震惊**非常合理也非常有价值**，因为这正是很多初入后端架构或网络领域的人会忽略的一个关键事实：

> **在私有网络（局域网）中，一个服务器的 IP 确实可以由自己决定，只要和整个网络的规则不冲突就行**

因为 **IP 地址只是个网络标识符**，在**私网（非公网）**中，并不由 ISP 或全球 IP 分配机构统一控制。

| **类型**  | **控制者**                         | **你是否能决定**       |
| --------- | ---------------------------------- | ---------------------- |
| 🌐 公网 IP | 由 ISP 或云服务商分配              | ❌ 不能随意决定         |
| 🛜 私网 IP | 局域网内自行管理（如 192.168.x.x） | ✅ 你自己可以分配和设置 |

**换种说法，这就像一个“内网自治国”：**

你的服务器、交换机、虚拟机，只要接在一个网段内，你完全有能力决定：

- 哪台机器是 192.168.1.10；
- 哪台机器当网关；
- 哪台机器监听什么端口、用什么协议……

这就好比在一个私有城市里，你自己规划门牌号，只要不撞门、不撞车，别人不管你

# 61、java对应cpp的stl就是集合框架吗

> **java 的集合框架（Collection Framework）是 Java 标准库中处理容器（集合类）的一整套接口 + 实现，对应于 C++ 的 STL（Standard Template Library）中的容器部分。**

但两者**不是完全对等**，它们各自的**设计哲学和组成结构**有明显差异。

| **功能**  | **Java（集合框架）**                        | **C++（STL）**                         |
| --------- | ------------------------------------------- | -------------------------------------- |
| 顺序容器  | List (如 ArrayList, LinkedList)             | vector, list, deque                    |
| 关联容器  | Set, Map (TreeSet, HashMap)                 | set, map, unordered_map, unordered_set |
| 栈 / 队列 | Stack, Queue, Deque                         | stack, queue, priority_queue, deque    |
| 哈希表    | HashMap, HashSet                            | unordered_map, unordered_set           |
| 排序树    | TreeMap, TreeSet                            | map, set（底层是红黑树）               |
| 接口设计  | 统一的接口体系（Collection, Map, Iterable） | 泛型模板机制，无统一接口体系           |

### **Java 集合框架的特点：**

- **面向对象**，一切都是接口和实现类；
- 强调接口抽象：如 List, Set, Map 是接口，ArrayList, HashMap 是实现；
- 有清晰的继承关系；
- 泛型虽然有，但是 **擦除型泛型**（运行时没有类型信息）；
- 更注重**类型安全、统一操作、扩展性**。

### **C++ STL 的特点：**

- 完全基于模板，**编译期类型确定**，效率高；
- 无统一接口抽象（没有 Collection 概念），靠模板约定语义；
- 强调的是 **性能和灵活性**，而不是面向对象；
- 不存在接口继承，容器直接暴露其成员函数；
- 算法与容器分离，**更函数式更底层**。

C++ 的 STL 还包括：

- **算法（std::sort, std::find, std::accumulate 等）**
- **迭代器模型（Input/Output/RandomAccessIterator）**
- **函数对象、适配器（std::bind, std::function 等）**
- **配接器（stack, queue 等是基于容器的封装）**

而 Java 的算法更多地封装在 Collections 工具类中，但不如 STL 系统化（直到 Java 8 才逐步引入 Stream 流式处理补足）。

# 62、java集合框架的接口、实现

### **1. Collection 系列（适用于元素集合）**

| **接口**        | **说明**                                | **典型实现类**                        |
| --------------- | --------------------------------------- | ------------------------------------- |
| Collection<E>   | 所有集合的根接口                        | 所有子类如 List、Set 等               |
| List<E>         | 有序、可重复                            | ArrayList, LinkedList, Vector, Stack  |
| Set<E>          | 无序、不可重复                          | HashSet, LinkedHashSet, TreeSet       |
| SortedSet<E>    | 排序 Set 接口（已被 NavigableSet 取代） | TreeSet                               |
| NavigableSet<E> | 可导航访问的排序 Set                    | TreeSet                               |
| Queue<E>        | 先进先出队列                            | LinkedList, PriorityQueue, ArrayDeque |
| Deque<E>        | 双端队列                                | ArrayDeque, LinkedList                |

### **2. Map 系列（适用于键值对）**

| **接口**                    | **说明**                              | **典型实现类**                             |
| --------------------------- | ------------------------------------- | ------------------------------------------ |
| Map<K,V>                    | 键值映射接口                          | HashMap, TreeMap, LinkedHashMap, Hashtable |
| SortedMap<K,V>              | 按 key 排序（已被 NavigableMap 取代） | TreeMap                                    |
| NavigableMap<K,V>           | 可导航访问的排序 Map                  | TreeMap                                    |
| ConcurrentMap<K,V>          | 支持并发访问                          | ConcurrentHashMap                          |
| ConcurrentNavigableMap<K,V> | 支持并发 + 有序访问                   | ConcurrentSkipListMap                      |

### **3. 并发集合（Java.util.concurrent）**

| **类型**               | **说明**     | **实现类**                              |
| ---------------------- | ------------ | --------------------------------------- |
| BlockingQueue          | 阻塞队列     | ArrayBlockingQueue, LinkedBlockingQueue |
| ConcurrentMap          | 并发哈希表   | ConcurrentHashMap                       |
| BlockingDeque          | 阻塞双端队列 | LinkedBlockingDeque                     |
| ConcurrentNavigableMap | 并发跳表     | ConcurrentSkipListMap                   |

# 63、通用的动态规划问题解决思路

### **1. 明确状态：选哪些变量来表示子问题？**

把问题拆分成**一系列子问题**，并找到一个函数或数组 dp[x] 表示某个子问题的答案。

- 典型例子：

  

  - dp[i] 表示以第 i 个元素结尾的最大子序列和；
  - dp[i][j] 表示考虑前 i 个物品、背包容量为 j 时的最大价值；
  - dp[i][j] 表示字符串 A 的前 i 个和字符串 B 的前 j 个是否匹配。

这一阶段最难，需要你抓住“状态变量”。

### **2. 定义初始条件（Base Case）**

给出最简单的情况，比如：

- 数组为空时的值；
- 背包容量为 0 时的值；
- 起始下标为 0 时的返回值；

> 比如：dp[0] = 0 表示背包容量为 0 时最大价值为 0。

### **3. 写出状态转移方程（核心）**

**用更小的子问题表达**当前子问题的答案。

- 例子：

  

  - 01 背包：dp[i][j] = max(dp[i-1][j], dp[i-1][j-w[i]] + v[i])
  - LIS：dp[i] = max(dp[j] + 1) for all j < i and nums[j] < nums[i]
  - 编辑距离：dp[i][j] = min(...)

  

**只要你能写出递推关系，这题就基本能做出来。**

### **4. 确定递推顺序（从哪到哪，二维还是一维）**

- 自底向上：常见于 tabulation；
- 自顶向下 + 记忆化搜索：递归 + memo；
- 判断是否可以滚动数组优化空间（背包类题常用）；

### **5. 返回目标结果**

- 一般是 dp[n]、dp[n][m]；
- 有时是 max(dp[i])；
- 或者从 DP 表中回溯出路径（输出方案）；

# 64、c++查漏补缺

## 1、**C++ 标准库定义的 4 个基础 IO 对象：**

| **名称** | **类型**     | **作用**                     | **默认绑定对象** |
| -------- | ------------ | ---------------------------- | ---------------- |
| cin      | std::istream | 标准输入流（读取输入）       | 键盘输入         |
| cout     | std::ostream | 标准输出流（正常输出）       | 屏幕显示         |
| cerr     | std::ostream | 标准错误流（错误输出）       | 屏幕显示         |
| clog     | std::ostream | 标准日志流（非紧急错误输出） | 屏幕显示         |

## 2、输出运算符<<

![image-20250615183029455](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250615183029455.png)

## 3、把流对象作为if判断条件

![image-20250615183423382](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250615183423382.png)

# 65、netplan的yaml

Netplan 是 Ubuntu 17.10+ 默认的网络配置框架，**通过 YAML 文件定义网络接口配置**，然后由后端工具（如 NetworkManager 或 systemd-networkd）负责应用这些配置

| **配置项**            | **作用**                          |
| --------------------- | --------------------------------- |
| ethernets:            | 配置以太网接口（如 eth0, enp3s0） |
| addresses:            | 分配静态 IP                       |
| dhcp4: / dhcp6:       | 是否启用 DHCP 自动分配 IPv4/IPv6  |
| gateway4: / gateway6: | 设置默认网关                      |
| nameservers:          | 配置 DNS                          |
| optional: true        | 启动时不等待该接口就绪            |

```yaml
network:
  version: 2
  ethernets:
    enp0s3:
      dhcp4: false
      addresses: [192.168.1.100/24]
      gateway4: 192.168.1.1
      nameservers:
        addresses: [8.8.8.8, 1.1.1.1]
```

```
network:
  version: 2
  ethernets:
    enp0s3:
      dhcp4: true
     
 这样配可以自动获取ip
```

# 66、如何配置当前虚拟机的服务器有稳定的ip呢？

这样配置了之后，如果外部服务的网络环境变化，其实会有问题导致联不通需要重新开启dhcp

**8.8.8.8 和 1.1.1.1 是非常特殊的 IP 地址**，它们是全球范围可用的**公共 DNS 服务器**，由两大互联网公司提供

- - ```
    1.1.1.1 和 1.0.0.1
    	•	归属：Cloudflare
    	•	特点：
    	•	更强调隐私（不会记录查询日志）
    	•	非常快（低延迟）
    	•	提供加密 DNS（DoH、DoT）
    	•	IPv6 对应地址：2606:4700:4700::1111
    ```

    ```
    1.1.1.1 和 1.0.0.1
    	•	归属：Cloudflare
    	•	特点：
    	•	更强调隐私（不会记录查询日志）
    	•	非常快（低延迟）
    	•	提供加密 DNS（DoH、DoT）
    	•	IPv6 对应地址：2606:4700:4700::1111
    ```

    - 更稳妥做法是：

      

      - 在国内环境下用 **阿里 DNS：223.5.5.5**
      - 或 **百度 DNS：180.76.76.76**

  

```
network:
  version: 2
  ethernets:
    enp0s3:
      dhcp4: false
      addresses:
        - 192.168.1.100/24       # 你希望设置的固定 IP（按实际网段改）
      gateway4: 192.168.1.1        # 路由器地址（你的网关）
      nameservers:
        addresses: [8.8.8.8, 1.1.1.1]  # 公共 DNS
        
        
        
```

# 67、linux的网络配置

```
1. 网卡和 IP 配置
2. DNS 配置
3. 路由表配置
4. Host 映射
5. 防火墙 / 安全策略
6. 系统内核参数（TCP/IP 栈）
7. 网络服务守护进程（如 NetworkManager、systemd-networkd）
```

## 0、网络配置概览

| **模块**              | **作用**                     | **典型工具/文件**                                |
| --------------------- | ---------------------------- | ------------------------------------------------ |
| 1. 网卡与地址配置     | 物理/虚拟网卡，IP 分配       | ip link, ip addr, /etc/netplan/                  |
| 2. 路由与转发规则     | 决定数据包如何走             | ip route, ip rule, /proc/sys/net/ipv4/ip_forward |
| 3. DNS 与主机名解析   | 域名 → IP 映射               | /etc/resolv.conf, /etc/hosts, systemd-resolved   |
| 4. 防火墙与包过滤     | 控制进/出方向与内容          | iptables, nftables, firewalld, ufw               |
| 5. 虚拟网络设备       | veth、bridge、tap 等虚拟接口 | ip link add ... type veth, brctl, nmcli          |
| 6. 网络命名空间与隔离 | 容器/沙箱网络环境隔离        | ip netns, unshare, nsenter, cni                  |

## 1、网卡和ip配置

为什么需要使用ip作为命令

```
1. ip 是更现代、更统一的工具
	•	ifconfig 属于早期的 net-tools 套件，已不再维护
	•	ip 属于 iproute2 套件，当前主流 Linux 发行版默认预装、持续维护
	ip 命令统一了所有网络配置操作
	•	ip addr 取代 ifconfig
	•	ip link 取代 ifconfig eth0 up/down
	•	ip route 取代 route
	•	ip rule 取代 ip rule add 的老命令组合

❗️很多新功能（如容器、Overlay 网络、VXLAN、策略路由）必须用 ip 配置，ifconfig 根本无法胜任
```

| **命令** | **描述**                          | **涉及网络层**   |
| -------- | --------------------------------- | ---------------- |
| ip link  | 显示/配置**网络接口**本身（网卡） | 数据链路层（L2） |
| ip addr  | 显示/配置**IP 地址**              | 网络层（L3）     |
| ip route | 显示/配置**路由表**               | 网络层/传输层    |

### 1.1、ip命令解读-ip addr

```
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:dc:bb:34 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.123/24 brd 192.168.1.255 scope global dynamic enp0s3
       valid_lft 86321sec preferred_lft 86321sec
    inet6 fe80::a00:27ff:fedc:bb34/64 scope link
       valid_lft forever preferred_lft forever
```

####  **第一行（网卡元信息）**

| **项**         | **含义**                                 |
| -------------- | ---------------------------------------- |
| 2:             | 接口编号（非设备名）                     |
| enp0s3         | 网卡名称（可能是 eth0/ens33 等）         |
| BROADCAST      | 支持广播                                 |
| MULTICAST      | 支持多播                                 |
| UP             | 网卡已启用                               |
| LOWER_UP       | 物理链路正常连接（有网线或虚拟设备连接） |
| mtu 1500       | 最大传输单元（默认1500字节）             |
| qdisc fq_codel | 队列调度算法（影响流控）                 |
| state UP       | 状态 UP（接口逻辑可用）                  |
| group default  | 网卡分组（高级用法）                     |
| qlen 1000      | 发送队列长度上限                         |

####   **第二行（MAC 地址和广播地址）**

| **项**                | **含义**         |
| --------------------- | ---------------- |
| link/ether            | 网卡类型为以太网 |
| 08:00:27:dc:bb:34     | 网卡的 MAC 地址  |
| brd ff:ff:ff:ff:ff:ff | 广播地址         |

#### **第三行（IPv4 地址信息）**

| **项**            | **含义**                                 |
| ----------------- | ---------------------------------------- |
| inet              | IPv4 地址                                |
| 192.168.1.123/24  | 分配的 IP 和子网                         |
| brd 192.168.1.255 | 广播地址                                 |
| scope global      | 地址作用域（global=公网，link=链路本地） |
| dynamic           | 动态分配（DHCP）                         |
| enp0s3            | 属于的网卡名称                           |

#### **第四行（IPv4 租期）**

| valid_lft     | IP 地址有效期                |
| ------------- | ---------------------------- |
| preferred_lft | 首选有效期（用于选择主地址） |

#### **IPv6 地址部分（如果启用 IPv6）**

### 1.2、ip link

其实就是ip addr的子集，目的主要是显示链路层的信息

### 1.3、ip route



显示网络层和链路层的信息

```
default via 192.168.231.186 dev enp0s5 proto dhcp src 192.168.231.71 metric 100
```

- default：默认路由，所有未知目的 IP 都从这走
- via 192.168.231.186：下一跳（默认网关 IP）
- dev enp0s5：使用的网络接口（网卡）
- proto dhcp：这条路由是 DHCP 协议分配的
- src 192.168.231.71：本机 IP 地址（用于发包时源地址）
- metric 100：优先级（数值越小优先级越高）

```
192.168.231.0/24 dev enp0s5 proto kernel scope link src 192.168.231.71 metric 100
```

- 192.168.231.0/24：本地局域网段（子网）
- dev enp0s5：使用该网卡访问此网段
- proto kernel：由内核自动生成（因为配置了 IP）
- scope link：链路级别作用域（仅本地 LAN 内有效）
- src 192.168.231.71：发往该网段时使用的源 IP

```
192.168.231.186 dev enp0s5 proto dhcp scope link src 192.168.231.71 metric 100
```

- 这是对“网关地址”本身的特殊路由（目标 IP 是网关）
- 指定通过 enp0s5 直连到网关 IP 192.168.231.186
- 有些 DHCP 服务会明确添加这一条，防止网关 IP 被错误路由

也就是说对当前的网络

| **项目**     | **值**                 |
| ------------ | ---------------------- |
| 本机 IP      | 192.168.231.71         |
| 子网         | 192.168.231.0/24       |
| 网关         | 192.168.231.186        |
| 网卡         | enp0s5                 |
| 路由来源     | DHCP 动态分配          |
| 默认路由走向 | 走网关 192.168.231.186 |

#### **所以你该怎么判断网络是否通：**

```
ping 192.168.231.186    # 网关通了，说明内网 OK
ping 8.8.8.8            # 公网通了，说明路由/网关 OK
ping www.baidu.com      # 域名通了，说明 DNS OK
```

> 这三项 ip route 输出的本质作用，是告诉系统：**出站流量应该从哪条路径（网卡+网关）发出去，流量走向怎么选。**

**默认路由**

- 所有目标地址不在你本地网段的 IP（比如 8.8.8.8、1.1.1.1）都会走这条路由。

- 相当于告诉系统：

  > “凡是不知道怎么走的，就发给 192.168.231.186（网关），它帮你转发。”

#### **192.168.231.0/24 dev enp0s5**

**本地局域网路由**

- 所有目的 IP 在你子网（如 192.168.231.50）范围内，直接发往网卡，不走网关。

- 作用：

  > “同一子网机器之间，直接通信，不需要经过网关。”

#### **192.168.231.186 dev enp0s5**

**专门一条“指向网关”的路由**

- 有些 DHCP 服务特意加这一条，确保你的网关地址（192.168.231.186）**一定能被识别为链路直连**。
- 防止某些复杂路由场景下，系统找不到怎么到达网关。

> 本质：让你能发包“到网关”，否则 default via 网关 也没意义

### 1.4、回环地址的作用

![image-20250630001603271](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250630001603271.png)

>  **“我自己连接我自己”** —— 只在本机内部生效，完全不经过网卡或网络栈。

| **场景**       | **举例**                   | **是否经过网络** |
| -------------- | -------------------------- | ---------------- |
| 测试本地服务   | curl http://127.0.0.1:8080 | ❌ 不出网卡       |
| 数据库连接     | psql -h 127.0.0.1 -p 5432  | ❌ 本地连接       |
| 应用绑定本地   | nginx 监听 127.0.0.1:80    | ❌ 外部无法访问   |
| 调试服务连通性 | telnet 127.0.0.1 9000      | ❌ 本机通道       |

别人从外部机器上 **永远无法访问你机器的 127.0.0.1**，因为：

- 回环接口 lo 是 **每台机器私有的**；
- 127.0.0.1 是一个保留 IP 段（整个 127.0.0.0/8 都是 loopback）；
- Linux 内核规定，访问 127.*.*.* 的数据包不能出本机。

| **场景**                           | **使用地址**                            |
| ---------------------------------- | --------------------------------------- |
| 只希望服务在本机运行，不被外部访问 | 127.0.0.1                               |
| 希望外部也能访问服务               | 0.0.0.0 或本机局域网 IP，如 192.168.1.x |
| 想指定绑定某张网卡（多网卡机器）   | 对应的 IP，如 10.0.0.5                  |

### 1.5、全0地址的作用

#### **1.** **作为目的地址：代表“默认路由目标”**

```
default via 192.168.1.1 dev eth0
```

> 这里的 default 就是 0.0.0.0/0 的缩写，意思是：



> ❗“所有目的 IP 不属于当前任何子网的，都发给这个网关。”

也就是：**“你不知道要发去哪儿时，就发去这里。”**

#### **2.** **作为监听地址：代表“监听所有 IP”**

### 1.6、当我ping 0.0.0.0的时候，谁在回复？

Linux 的 ping 工具内部调用 getaddrinfo() 解析目标地址。

而在一些 glibc 实现中，0.0.0.0 被认为是无效目标地址，于是：

1. **被重定向为回环地址 127.0.0.1**
2. 从用户视角看，ping 0.0.0.0 就变成了 ping 127.0.0.1

这是一种**内核容错逻辑 + 用户态工具兼容行为**，它的设计目标是防止你对一个“无意义目标”发包时直接失败，而是尽量让你“感觉有回应”

### 1.7、ip monitor

```
2409:8962:fa2:e0c::6e dev enp0s5 lladdr aa:2e:34:5d:7f:59 router STALE 
fe80::a82e:34ff:fe5d:7f59 dev enp0s5 lladdr aa:2e:34:5d:7f:59 router STALE 
192.168.231.186 dev enp0s5 lladdr aa:2e:34:5d:7f:59 PROBE 
192.168.231.186 dev enp0s5 lladdr aa:2e:34:5d:7f:59 REACHABLE
```

ip monitor 输出，是 Linux 实时监听网络状态变化的结果，主要用于**调试网络连通性、邻居发现、ARP/NDP 状态变动**等场景

| **字段** | **含义**                               |
| -------- | -------------------------------------- |
| IP地址   | 邻居设备的 IP 地址（IPv4 / IPv6）      |
| dev      | 本机使用的网卡                         |
| lladdr   | 邻居设备的 MAC 地址（ARP 或 NDP 获取） |
| router   | 表示这个邻居是默认网关                 |
| <状态>   | **邻居项（ARP/NDP 状态）**，见下文     |

#### **邻居项状态（邻居表，ARP/NDP）**

| **态**     | **含义**                           |
| ---------- | ---------------------------------- |
| REACHABLE  | 刚刚通信成功，连接正常             |
| STALE      | 超时未使用，等待下次通信确认       |
| PROBE      | 正在探测对方是否还在线（ARP 请求） |
| DELAY      | 系统观察中，等待上层使用           |
| FAILED     | 无法连接，ARP 失败                 |
| INCOMPLETE | 地址解析未完成                     |
| NOARP      | 禁用 ARP                           |

```
192.168.231.186 dev enp0s5 lladdr aa:2e:34:5d:7f:59 PROBE
```

- 系统在尝试通过 ARP 请求探测 192.168.231.186 是否还在线

```
192.168.231.186 dev enp0s5 lladdr aa:2e:34:5d:7f:59 REACHABLE
```

- 得到回应，邻居在线，链路畅通

### 1.8、etc/netplan/

/etc/netplan/ 是 Ubuntu（以及一些基于它的系统）在 17.10 版本之后引入的 **网络配置系统的核心目录**，用来统一管理网络接口的配置，**替代了早期的 /etc/network/interfaces**。

> netplan 是 Ubuntu 推出的 YAML 网络配置系统，它的配置文件就放在 /etc/netplan/ 目录下，用来描述网卡、IP、DHCP、网关、DNS 等网络设置

```
network:
  version: 2
  renderer: networkd
  ethernets:
    enp0s3:
      dhcp4: no
      addresses:
        - 192.168.1.100/24
      gateway4: 192.168.1.1
      nameservers:
        addresses: [8.8.8.8, 1.1.1.1]
```

- 为网卡 enp0s3 设置静态 IP、默认网关、DNS 服务器
- 禁用 DHCP
- 使用 systemd-networkd 作为后端渲染器（renderer）

```
/etc/netplan/*.yaml
       ↓
sudo netplan apply
       ↓
转换为 systemd-networkd / NetworkManager 的配置
       ↓
应用网络设置（如分配 IP、设路由、启网卡）
```

![image-20250630004537231](https://raw.githubusercontent.com/t1m3saver/picBed/main/mac/image-20250630004537231.png)

## 2. 路由与转发规则

```
┌──────────────────────────────┐
│ 网卡（interface）           │ ← 通过 `ip link` 管理
├──────────────────────────────┤
│ IP 配置（addr/gateway）     │ ← 通过 `ip addr`, `ip route` 管理
├──────────────────────────────┤
│ 路由表（Routing Table）      │ ← 控制 IP 包走哪条路径（`ip route`）
├──────────────────────────────┤
│ 策略路由（Policy Routing）   │ ← 多表+规则（`ip rule`, `ip route add table`）
├──────────────────────────────┤
│ 转发能力开关                │ ← `/proc/sys/net/ipv4/ip_forward`
└──────────────────────────────┘
```

### **1、转发能力开关（是否允许中转数据包）**

```
echo 1 > /proc/sys/net/ipv4/ip_forward
# 或永久启用：
echo "net.ipv4.ip_forward = 1" >> /etc/sysctl.conf
sysctl -p
```

### 2、traceroute

```
liu@liu-vm0:~/code/CHAT$ traceroute openai.com
traceroute to openai.com (172.64.154.211), 30 hops max, 60 byte packets
 1  _gateway (192.168.231.186)  3.661 ms  3.548 ms  3.526 ms
 2  * * *
 3  172.21.1.1 (172.21.1.1)  47.652 ms  47.636 ms  47.621 ms
 4  192.168.243.57 (192.168.243.57)  45.264 ms 192.168.243.45 (192.168.243.45)  45.250 ms  45.232 ms
 5  * * *
 6  218.200.234.41 (218.200.234.41)  45.147 ms 218.200.234.53 (218.200.234.53)  36.464 ms  36.350 ms
 7  221.183.47.105 (221.183.47.105)  36.986 ms  28.615 ms  28.530 ms
 8  221.183.40.141 (221.183.40.141)  74.578 ms 221.183.40.61 (221.183.40.61)  64.183 ms  63.708 ms
 9  221.183.89.9 (221.183.89.9)  63.673 ms 221.183.89.45 (221.183.89.45)  67.566 ms *
10  * * *
11  221.183.89.173 (221.183.89.173)  102.160 ms  95.216 ms  95.146 ms
12  223.120.3.185 (223.120.3.185)  180.672 ms  176.342 ms 223.120.22.109 (223.120.22.109)  82.097 ms
13  223.120.3.122 (223.120.3.122)  114.153 ms 223.120.2.62 (223.120.2.62)  88.100 ms 223.120.3.122 (223.120.3.122)  173.706 ms
14  223.119.6.101 (223.119.6.101)  165.837 ms 223.119.6.105 (223.119.6.105)  75.063 ms  74.988 ms
15  172.64.154.211 (172.64.154.211)  74.968 ms  77.395 ms  81.359 ms
```

你这条 traceroute openai.com 的输出，说明了你从本地虚拟机访问 OpenAI（Cloudflare CDN）的整个链路路径，**几乎完整跑通了全球骨干链路，最终抵达目标 IP（172.64.154.211）**，这是一个典型的 **“公网链路跨运营商出境”** 的例子

```
3  172.21.1.1 ...
4  192.168.243.57 ...
```

- 172.21.x.x 和 192.168.x.x 都是私有地址段
- 表示你还在 **运营商 NAT 网络中**，流量尚未出公网
- 说明你本地运营商做了 **CGNAT（Carrier Grade NAT）**

**跳数 5：再次超时**：运营商内部服务器不回应

```
6  218.200.234.x
7  221.183.47.x
8  221.183.40.x
9  221.183.89.x
```

- 218.200.*.* → 中国电信公网
- 221.183.*.* → 中国移动骨干网

你可以看到流量从运营商内部 NAT 出口切换到了中国移动骨干。

> OpenAI 的目标 CDN 路由选择了 **中国移动的出口线路**，可能因为地理位置、BGP 最优路径或合作关系。

```
11  221.183.89.173
12  223.120.3.185
13  223.120.3.122
14  223.119.6.105
```

- 223.120.*.* 和 223.119.*.* 是 **中国移动国际出口（CMI）**
- 表示你流量正式出境了！现在走的是中国移动的国际骨干网（往亚洲节点出发）

```
15  172.64.154.211
```

- **抵达目标 IP**，即 OpenAI 在 Cloudflare 的接入边缘节点
- 延迟 74~81ms，说明你连接的是一个 **亚洲（可能是香港或新加坡）CDN 节点**，而非美国本土
